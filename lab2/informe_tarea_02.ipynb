{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrega 2, Grupo 02 - Aprendizaje Bayesiano\n",
        "\n",
        "- Santiago Alaniz,  5082647-6, santiago.alaniz@fing.edu.uy\n",
        "- Bruno De Simone,  4914555-0, bruno.de.simone@fing.edu.uy\n",
        "- María Usuca,      4891124-3, maria.usuca@fing.edu.uy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivo\n",
        "\n",
        "Implementar un algoritmo de predicción de palabras utilizando Naive Bayes. El modelo se entrenará con datos de conversaciones de WhatsApp y se probará en un simulador de cliente. \n",
        "\n",
        "El algoritmo debe ser capaz de recomendar palabras basadas en las últimas N palabras ingresadas en una frase, donde N es un hiperparámetro que se variará para evaluar el desempeño del modelo. Además, el modelo se reentrenará al finalizar cada frase para adaptarse a nueva evidencia. \n",
        "\n",
        "La implementación debe ser eficiente en términos de uso de CPU, utilizando las estructuras de datos más adecuadas en Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diseño"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carga del dump de conversaciones en un grupo de WhatsApp\n",
        "\n",
        "En la letra del laboratorio se menciona que se puede acceder al dump en formato `.csv` pero esto es un error en la letra. *WhatsApp* exporta las conversaciones en formato `.txt`.\n",
        "\n",
        "Esto complejiza la carga de los datos ya que no podemos asumir que cada linea del archivo es una entrada del log.\n",
        "\n",
        "Detectamos el siguiente patron en el archivo de texto\n",
        "\n",
        "```\n",
        "  [dd/mm/aaaa hh:mm:ss] <nombre>: <mensaje>\n",
        "    ***\n",
        "  [dd/mm/aaaa hh:mm:ss] <nombre>: <mensaje>\n",
        "```\n",
        "\n",
        "Nos valemos del modulo `src.regex` para definir la expresion regular que detecta el patron y extrae los mensajes (`LOG_ENTRY_PATTERN`).\n",
        "\n",
        "`LOG_ENTRY_PATTERN = f'{metadata_pattern}{message_pattern}(?=\\n{metadata_pattern}|$)':`\n",
        "\n",
        "Esta expresion regular captura el contenido de cada entrada del log en dos grupos: `metadata` y `message`. \n",
        "\n",
        "- El grupo `metadata` captura la fecha y hora de la entrada, el nombre del usuario o el numero de telefono. \n",
        "- El grupo `message` captura el mensaje en si mismo y es el que nos interesa recuperar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from src.whatsapp_regex import LOG_ENTRY_PATTERN\n",
        "import random\n",
        "\n",
        "SEED = 42069\n",
        "FILE_PATH = './assets/chat.txt'\n",
        "PATTERN = LOG_ENTRY_PATTERN\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "with open(FILE_PATH, 'r', encoding='utf-8') as file:\n",
        "  data = file.read()\n",
        "\n",
        "matches = re.findall(PATTERN, data)\n",
        "data = [ match[1] for match in matches ]\n",
        "\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesamiento de datos\n",
        "\n",
        "Para un algoritmo de sugerencia de palabras basado en aprendizaje bayesiano, el preprocesamiento de los datos es crucial para obtener resultados significativos. En nuestro caso, se compone de los siguientes pasos:\n",
        "\n",
        "- **Tokenización ordenada**: Para que el algoritmo pueda identificar correctamente las palabras y su posición en la oración, es necesario dividir la oración en [tokens](https://es.wikipedia.org/wiki/Token).\n",
        "- **Conversión a minúsculas**: Para que el algoritmo no trate las palabras como diferentes solo debido a las diferencias de mayúsculas y minúsculas.\n",
        "- **Eliminación de caracteres especiales, numericos, emojis**: Estos componentes lexicos y semanticos no aportan información relevante para el modelo que busca sugerir palabras.\n",
        "- **Relajar tildes con [unidecode](https://pypi.org/project/Unidecode/)**: Para que el modelo no distinga palabras con tildes de palabras sin tildes. Teniendo en cuenta que en los mensajes de WhatsApp es muy común que se omitan las tildes.\n",
        "- **Validacion de palabras en espanol con un [corpus](http://universal.elra.info/product_info.php?cPath=42_43&products_id=1509)**: Para descartar palabras que no pertenecen al idioma español, chequeamos su existencia en un corpus. Esto es importante para evitar que el modelo sugiera palabras en otros idiomas o palabras que no existen.\n",
        "\n",
        "Construimos la clase `src.G02Preprocessor` para encapsular el preprocesamiento de los datos y realizar los pasos mencionados anteriormente con mayor facilidad y control.\n",
        "\n",
        "``` python\n",
        "class G02Preprocessor:\n",
        "    def __init__(self):\n",
        "        self.V_SPA = set([unidecode(word.lower()) for word in cess_esp.words()])\n",
        "\n",
        "\n",
        "    def apply(self, data, data_test=True):\n",
        "        preprocessed_data = []\n",
        "\n",
        "        for message in data:\n",
        "            words = word_tokenize(message, language='spanish')\n",
        "            words = [unidecode(word.lower()) for word in words]\n",
        "            words = [word for word in words if word.isalpha()]\n",
        "            if not words: continue\n",
        "            if data_test:\n",
        "                words = [word for word in words if word in self.V_SPA]\n",
        "            if not words: continue\n",
        "\n",
        "            preprocessed_data.append(words)\n",
        "\n",
        "        return preprocessed_data\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.preprocessing import G02Preprocessor\n",
        "\n",
        "\n",
        "preprocessor = G02Preprocessor()\n",
        "ejemplo = random.choice(data)\n",
        "\n",
        "\n",
        "print(f'\\\n",
        "Palabras del diccionario cess_esp: {len(preprocessor.V_SPA)} \\n\\\n",
        "Frase de ejemplo: \\n {ejemplo} \\n\\\n",
        "Frase de ejemplo preprocesada: {preprocessor.apply([ejemplo])} \\n'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Particionamiento de datos\n",
        "\n",
        "Antes de continuar, separaremos el conjunto de datos para luego poder entrenar y evaluar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED_NUMBER = 342\n",
        "TEST_SIZE   = 0.4\n",
        "DEVEL_SIZE  = 0.5\n",
        "\n",
        "train, test = train_test_split(data, test_size= TEST_SIZE, random_state= SEED_NUMBER)\n",
        "test, devel = train_test_split(test, test_size= DEVEL_SIZE, random_state= SEED_NUMBER)\n",
        "\n",
        "print (train)\n",
        "print (test)\n",
        "print (devel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Algoritmo\n",
        "\n",
        "El algoritmo a implementar es un [clasificador bayesiano naive](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo). Con la incorporación de un meta-pararametro `N`, que indica la cantidad de palabras anteriores a considerar para la predicción de la siguiente palabra. \n",
        "\n",
        "En la letra del laboratorio se menciona que este algoritmo es intensivo en CPU, es parte de la consigna del laboratorio implementar el algoritmo de la manera más eficiente posible.\n",
        "\n",
        "Detectamos las siguientes tareas para cumplir con la consigna:\n",
        "\n",
        "- **Definir las estructuras de datos**: Debemos diseñar las estructuras de datos que nos permitan almacenar la información necesaria para el funcionamiento del algoritmo. De forma tal que el acceso a la información y los calculos sean lo más eficientes posibles.\n",
        "- **Modulo auxiliar `naive_bayes_utils.py`**: Una vez diseñadas las estructuras de datos, debemos implementarlas, proponemos hacerlo siguiendo un enfoque modular, donde se plasmen las ideas discutidas en el punto anterior.\n",
        "- **Clase `G02NaiveBayesClassifier`**: Una vez implementadas las estructuras de datos, debemos implementar la clase `G02NaiveBayesClassifier` que encapsula el algoritmo de clasificación y mantiene todo el aparato auxiliar encapsulado bajo la misma clase. Esta clase esta definida en el modulo `bayesian_learning.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Definir las estructuras de datos\n",
        "\n",
        "Nuestro modelo busca sugerir la palabra más probable dado un contexto de N palabras anteriores. Esto es coincidente con el objetivo mas general de los clasificadores bayesianos, que es encontrar la hipótesis más probable dado un conjunto de evidencias. (`h_map`)\n",
        "\n",
        "- `h_map` = argmax<sub>h</sub> P(h|D) = argmax<sub>h</sub> P(D|h) P(h) / P(D)\n",
        "\n",
        "Los clasificadores bayesianos naive asumen que las evidencias son independientes entre si, por lo que la probabilidad de la hipótesis MAP se puede expresar como el producto de las probabilidades de cada evidencia dada la hipótesis multiplicado por la probabilidad de la hipótesis.\n",
        "\n",
        "- `h_map` = argmax<sub>h</sub> P(D|h) P(h) / P(D) = argmax<sub>h</sub> P(D|h) P(h) = argmax<sub>h</sub> P(d<sub>1</sub>|h) ... P(d<sub>n</sub>|h) P(h)\n",
        "\n",
        "Nuestro meta-parámetro `N` indica la cantidad de palabras anteriores a considerar para la predicción de la siguiente palabra. Es decir, `N` es la cantidad de evidencias que consideramos para calcular la probabilidad de la hipótesis (la palabra a sugerir).\n",
        "\n",
        "Si bien un modelo bayesiano naive simplifica los calculos, diseñar estructuras de datos y algoritmos eficientes para calcular las probabilidades no es trivial. Proponemos las siguientes estructuras de datos para almacenar la información necesaria para el funcionamiento del algoritmo:\n",
        "\n",
        "- `V`: Vocabulario de palabras en el conjunto de entrenamiento.\n",
        "- `F_h`: Frecuencia de cada hipótesis (palabra) en el conjunto de entrenamiento.\n",
        "- `F_hD`: Frecuencia de cada evidencia (palabra anterior) dado una hipótesis (palabra) en el conjunto de entrenamiento. A diferencia de `F_h`, `F_hD` es un diccionario de diccionarios y es afectado por el meta-parámetro `N`, ya que la cantidad de evidencias a considerar depende de `N`. Por ejemplo, si `N=4` y la hipótesis es `h`, `F_hD[h]` es un diccionario que contiene la frecuencia de cada combinación de 4 palabras anteriores a `h` en el conjunto de entrenamiento.\n",
        "\n",
        "Mantener las frecuencias es computacionalmente hablando mas eficiente que mantener las probabilidades. Se plantea un esquema de actualizacion y uso a 'demanda', donde las prrobabilidades de h_map se calculan 'on the fly'.\n",
        "\n",
        "*Nota*:\n",
        "\n",
        "El enfoque de construccion de estas estructuras es greedy en el sentido de que si la frase desafortunadamente no tiene el largo de palabras necesario toma hasta donde puede. Por ejemplo, si `N=4` y la frase es `['hola', 'como', 'estas']`, el modelo solo considera las palabras `['hola', 'como']` para la prediccion de la siguiente palabra. Esto es un trade-off entre eficiencia y exactitud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modulo auxiliar `naive_bayes_utils.py`\n",
        "\n",
        "El modulo `naive_bayes_utils.py` encapsula las estructuras de datos y los algoritmos auxiliares necesarios para el funcionamiento del clasificador bayesiano naive. \n",
        "\n",
        "Estas estructuras de datos fueron definidas en el punto anterior y fueron implementadas en el modulo `naive_bayes_utils.py` de la siguiente manera:\n",
        "\n",
        "- `build(data, N)`: Genera contadores para las frecuencias de palabras individuales (`F_h`) y pares de palabras (`F_hD`) en un conjunto de datos de texto. Devuelve el número total de palabras (`V`), junto con los contadores.\n",
        "- `p_h(h, V, F_h, data)`: Calcula una probabilidad ajustada para la ocurrencia de una palabra específica (`h`) en el conjunto de datos.\n",
        "- `p_hD(d, h, V_SPA, F_h, F_hD, m=1)`: Calcula la probabilidad condicional de que una palabra (`d`) preceda a otra (`h`) usando m-stimador. \n",
        "\n",
        "*Nota*: \n",
        "\n",
        "En la firma de `p_h` abusamos de la notacion, enralidad estamos calculando la metrica tf-idf. Consideramos que esta metrica es mucho mas significativa que simplemente la frecuencia de la hipotesis en el conjunto de entrenamiento. [TF-IDF](https://es.wikipedia.org/wiki/Tf-idf) es una métrica comúnmente usada en el procesamiento del lenguaje natural para valorar la importancia de una palabra en un corpus en relación con su frecuencia en documentos específicos.\n",
        "\n",
        "En la implementacion de `p_hD` se utiliza un m-stimador para evitar que la probabilidad condicional sea cero. Asumimos equiprobabilidad a priori de la evidencia, siendo esta 1/len(V_SPA) donde V_SPA es el vocabulario de palabras en español que utilizamos en el preprocesamiento de los datos. [cess_esp](http://universal.elra.info/product_info.php?cPath=42_43&products_id=1509)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.naive_bayes_utils import *\n",
        "\n",
        "V, F_h, F_hD = build(preprocessor.apply(train), N=4)\n",
        "\n",
        "results = {\n",
        "  'V': V,\n",
        "  'F_h': F_h,\n",
        "  'F_hD': F_hD,\n",
        "}\n",
        "\n",
        "for key, value in results.items():\n",
        "  print(f'{key}: {value}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clase `G02NaiveBayesClassifier`\n",
        "\n",
        "La clase `G02NaiveBayesClassifier` es nuestra implementación del algoritmo de clasificación Naive Bayes con un enfoque en el procesamiento del lenguaje natural. Estos son los métodos principales de la clase:\n",
        "\n",
        "##### `__init__(self, data, N=1, M=1)`\n",
        "\n",
        "Inicializa el clasificador:\n",
        "\n",
        "- `data`: El conjunto de datos sobre el cual se construirá el modelo.\n",
        "- `N`: El tamaño del contexto para el modelo.\n",
        "- `M`: Un parámetro para suavizado.\n",
        "  \n",
        "Se realiza la preprocesamiento de los datos y se construyen las estadísticas (frecuencias de términos y pares de términos) utilizando la función `build`.\n",
        "\n",
        "##### `predict(self, sentence)`\n",
        "\n",
        "Realiza una predicción para una oración dada:\n",
        "\n",
        "- `sentence`: La oración a clasificar.\n",
        "\n",
        "Calcula el logaritmo de las probabilidades de cada palabra en el vocabulario dada la oración y selecciona la palabra con la mayor log-probabilidad que no esté ya en la oración. Somos conscientes que esta ultima modificacion no es ortodoxa, pero nos parecio una buena que el modelo no sugiera palabras que ya estan en la oracion.\n",
        "\n",
        "##### `update(self, new_sentence)`\n",
        "\n",
        "Actualiza el modelo con una nueva oración:\n",
        "\n",
        "- `new_sentence`: La nueva oración para actualizar el modelo.\n",
        "\n",
        "Realiza preprocesamiento en la nueva oración y actualiza las estadísticas del modelo (`F_h` y `F_hD`). También actualiza el conjunto de vocabulario y el número total de términos.\n",
        "\n",
        "La clase también utiliza el preprocesador (`G02Preprocessor`) definido en el punto anterior para realizar el preprocesamiento de los datos.\n",
        "\n",
        "*Nota*:\n",
        "\n",
        "La decision de actualizar el Vocabulario en Español (`V_SPA`) con las palabras de la nueva oracion es discutible. Por un lado, es posible que la nueva oracion contenga palabras que no pertenecen al idioma español, como tambien que el usuario escriba palabras del espanol poco usuales y que estas no esten dentro del compendio del `cess_esp`. \n",
        "\n",
        "Por eso, asumimos que el usuario del cliente escribe en español (aunque se tome libertades a la hora de asignar tildes)\n",
        "\n",
        "El siguiente codigo provee un benchmarking de la implementacion del algoritmo de clasificacion bayesiana naive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.bayesian_learning import G02NaiveBayesClassifier\n",
        "import time\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "clf = G02NaiveBayesClassifier(train, N=1)\n",
        "print(f'[INIT]  Tiempo de ejecución: {time.time() - start:.4f}s')\n",
        "test = ['horarios']\n",
        "\n",
        "print(' '.join(test))\n",
        "\n",
        "start = time.time()\n",
        "for i in range(2): test.append(clf.predict(test))\n",
        "print(f'[PREDICT] Tiempo de ejecución: {time.time() - start:.4f}s')\n",
        "\n",
        "print(f'        V: {clf.V_DATA} \\\n",
        "    \\n          F_h[{test[1]}]: {clf.F_h[test[1]]} \\\n",
        "    \\n          F_hD[{test[1]}][{test[0]}]: {clf.F_hD[test[1]][test[0]]} \\\n",
        "    \\n          F_h[{test[2]}]: {clf.F_h[test[2]]} \\\n",
        "    \\n          F_hD[{test[2]}][{test[1]}]: {clf.F_hD[test[2]][test[1]]}')\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "print(' '.join(test))\n",
        "\n",
        "clf.update(' '.join(test))\n",
        "print(f'[UPDATE]  Tiempo de ejecución: {time.time() - start:.4f}s')\n",
        "\n",
        "print(f'        V: {clf.V_DATA} \\\n",
        "    \\n          F_h[{test[1]}]: {clf.F_h[test[1]]} \\\n",
        "    \\n          F_hD[{test[1]}][{test[0]}]: {clf.F_hD[test[1]][test[0]]} \\\n",
        "    \\n          F_h[{test[2]}]: {clf.F_h[test[2]]} \\\n",
        "    \\n          F_hD[{test[2]}][{test[1]}]: {clf.F_hD[test[2]][test[1]]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluación\n",
        "\n",
        "En cualquier laboratorio o proyecto de investigación, la sección de evaluación es crucial para entender cómo se mide el rendimiento del modelo y qué métricas son relevantes para el problema en cuestión. Sin embargo, la naturaleza planteada en la letra del laboratorio no permite una evaluación cuantitativa del modelo. Por lo tanto, proponemos una evaluación cualitativa del modelo.\n",
        "\n",
        "No sabemos como encapsular el hecho de que el modelo esta \"sugeriendo bien\" bajo una de las metricas presentada en la metodologia. Dado que es una percepción subjetiva del usuario que esta manteniendo una conversación con el modelo.\n",
        "\n",
        "Lo que si podemos hacer, adoptando una evaluacion ya mas relajada. Dada una sesion de cliente, cuantificar la cantidad de veces que el modelo sugiere una palabra que el usuario considera correcta.\n",
        "\n",
        "Alterando el tamaño de la ventana de palabras `N`  buscamos encontrar un equilibrio entre las siguientes propiedades deseables:\n",
        "\n",
        "- **Memoria**: El modelo debe ser capaz de sugerir palabras que tengan coherencia con el grupo de Whatsapp de donde se extrajeron los datos.\n",
        "\n",
        "- **Adaptacion**: El modelo debe ser capaz de adaptarse a la nueva evidencia, y mejorar su performance, sugiriendo palabras que tengan coherencia con la sesion de chat que se esta simulando.\n",
        "\n",
        "Esta particularidad en la evaluación del modelo, tambien impacta en la definición de los conjuntos de entrenamiento, prueba y evaluación.\n",
        "\n",
        "El clasificador bayesiano se construye a partir de un conjunto de entrenamiento. En nuestro caso, el conjunto de entrenamiento es el conjunto de mensajes de un grupo de WhatsApp. No hay conjunto de prueba ni conjunto de evaluación. El modelo se evalúa en tiempo real, mientras el usuario (en primera instancia nosotros y luego el cuerpo docente) interactúa con el modelo y evalúa la calidad de las sugerencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.bayesian_learning import G02NaiveBayesClassifier  \n",
        "N = 4\n",
        "M = 1\n",
        "\n",
        "devel = preprocessor.apply(devel)\n",
        "clf = G02NaiveBayesClassifier(train, N=N, M=M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Falta jugar con N, hacerlo para todo devel? update?\n",
        "- Armar una frase que no este en el modelo e ir probando cuanto demora en aprenderla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 7 #28\n",
        "\n",
        "palabras_acertadas = 0\n",
        "frase = []\n",
        "frase_sugerida = []\n",
        "palabra_sugerida = devel[i][0]\n",
        "\n",
        "for word in devel[i]:\n",
        "    if (word == palabra_sugerida): palabras_acertadas+=1    \n",
        "    frase.append(word)\n",
        "    frase_sugerida.append(palabra_sugerida)\n",
        "    palabra_sugerida = clf.predict(frase)\n",
        "\n",
        "print(\"Frase original: \"+ \" \".join(frase))\n",
        "print(\"Frase sugerida: \"+ \" \".join(frase_sugerida))\n",
        "print(\"Cantidad de palabras acertadas: \", palabras_acertadas-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimentación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simulador de cliente.\n",
        "\n",
        "El experimento consiste en evaluar los distintos hiperparametros del modelo.\n",
        "\n",
        "El siguiente script permite simular el comportamiento de un cliente que escribe frases, fue proporcionado por el cuerpo docente. Es de utilidad para experimentar con modelo, ya que permite ingresar frases y ver las sugerencias que el modelo realiza.\n",
        "\n",
        "**Nota:**\n",
        "\n",
        "El comportamiento del siguiente script en `VSCode` es diferente al comportamiento en la terminal. En VSCode, el script omite entradas, se desfasa y hace que el analisis de los resultados sea dificil. Por lo tanto, recomendamos ejecutar el script en la terminal. (`client.py`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
        "- ¿cuándo se dieron los mejores resultados del jugador?\n",
        "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
        "- ¿cómo mejoraría los resultados?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
