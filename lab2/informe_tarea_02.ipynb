{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrega 2, Grupo 02 - Aprendizaje Bayesiano\n",
        "\n",
        "- Santiago Alaniz,  5082647-6, santiago.alaniz@fing.edu.uy\n",
        "- Bruno De Simone,  4914555-0, bruno.de.simone@fing.edu.uy\n",
        "- María Usuca,      4891124-3, maria.usuca@fing.edu.uy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivo\n",
        "\n",
        "Implementar un algoritmo de predicción de palabras utilizando Naive Bayes. El modelo se entrenará con datos de conversaciones de WhatsApp y se probará en un simulador de cliente. \n",
        "\n",
        "El algoritmo debe ser capaz de recomendar palabras basadas en las últimas N palabras ingresadas en una frase, donde N es un hiperparámetro que se variará para evaluar el desempeño del modelo. Además, el modelo se reentrenará al finalizar cada frase para adaptarse a nueva evidencia. \n",
        "\n",
        "La implementación debe ser eficiente en términos de uso de CPU, utilizando las estructuras de datos más adecuadas en Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diseño"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carga del dump de conversaciones en un grupo de WhatsApp\n",
        "\n",
        "En la letra del laboratorio se menciona que se puede acceder al dump en formato `.csv` pero esto es un error en la letra. *WhatsApp* exporta las conversaciones en formato `.txt`.\n",
        "\n",
        "Esto complejiza la carga de los datos ya que no podemos asumir que cada linea del archivo es una entrada del log.\n",
        "\n",
        "Detectamos el siguiente patron en el archivo de texto\n",
        "\n",
        "```\n",
        "  [dd/mm/aaaa hh:mm:ss] <nombre>: <mensaje>\n",
        "    ***\n",
        "  [dd/mm/aaaa hh:mm:ss] <nombre>: <mensaje>\n",
        "```\n",
        "\n",
        "Nos valemos del modulo `src.regex` para definir la expresion regular que detecta el patron y extrae los mensajes (`LOG_ENTRY_PATTERN`).\n",
        "\n",
        "`LOG_ENTRY_PATTERN = f'{metadata_pattern}{message_pattern}(?=\\n{metadata_pattern}|$)':`\n",
        "\n",
        "Esta expresion regular captura el contenido de cada entrada del log en dos grupos: `metadata` y `message`. \n",
        "\n",
        "- El grupo `metadata` captura la fecha y hora de la entrada, el nombre del usuario o el numero de telefono. \n",
        "- El grupo `message` captura el mensaje en si mismo y es el que nos interesa recuperar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from src.whatsapp_regex import LOG_ENTRY_PATTERN\n",
        "\n",
        "FILE_PATH = './assets/chat.txt'\n",
        "PATTERN = LOG_ENTRY_PATTERN\n",
        "\n",
        "with open(FILE_PATH, 'r', encoding='utf-8') as file:\n",
        "  data = file.read()\n",
        "\n",
        "matches = re.findall(PATTERN, data)\n",
        "data = [ match[1] for match in matches ]\n",
        "\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesamiento de datos\n",
        "\n",
        "Para un algoritmo de sugerencia de palabras basado en aprendizaje bayesiano, el preprocesamiento de los datos es crucial para obtener resultados significativos. En nuestro caso, se compone de los siguientes pasos:\n",
        "\n",
        "1. **Conversión a minúsculas**: Para que el algoritmo no trate las palabras como diferentes solo debido a las diferencias de mayúsculas y minúsculas.\n",
        "2. **Eliminación de caracteres especiales, numericos, emojis**: Estos componentes lexicos y semanticos no aportan información relevante para el modelo que busca sugerir palabras.\n",
        "3. **Eliminación de [stopwords](https://es.wikipedia.org/wiki/Palabra_vac%C3%ADa)**: Estas palabras aparecen con mucha frecuencia en el lenguaje natural independientemente del contexto, por lo que no aportan información relevante para el modelo.\n",
        "4. **Tokenización ordenada**: Para que el algoritmo pueda identificar correctamente las palabras y su posición en la oración, es necesario dividir la oración en [tokens](https://es.wikipedia.org/wiki/Token).\n",
        "5. **Cruzamiento de palabras con un [corpus](http://universal.elra.info/product_info.php?cPath=42_43&products_id=1509)**: Para descartar palabras que no pertenecen al idioma español, chequeamos su existencia en un corpus. Esto es importante para evitar que el modelo sugiera palabras en otros idiomas o palabras que no existen.\n",
        "6. **Relajar tildes**: Para que el modelo no distinga palabras con tildes de palabras sin tildes. Teniendo en cuenta que en los mensajes de WhatsApp es muy común que se omitan las tildes.\n",
        "\n",
        "Construimos la clase `src.G02Preprocessor` para encapsular el preprocesamiento de los datos y realizar los pasos mencionados anteriormente con mayor facilidad y control.\n",
        "\n",
        "*Nota:* \n",
        "\n",
        "La lista resultado del preprocesamiento tiene un tamaño menor a la lista original. Esto se debe a que el preprocesamiento descarta mensajes que no cumplen con los criterios de preprocesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.preprocessing import G02Preprocessor\n",
        "\n",
        "preprocessor = G02Preprocessor()\n",
        "preprocessed_data = preprocessor.apply(data)\n",
        "\n",
        "preprocessed_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Algoritmo\n",
        "\n",
        "El algoritmo a implementar es un [clasificador bayesiano naive](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo). Con la incorporación de un meta-pararametro `N`, que indica la cantidad de palabras anteriores a considerar para la predicción de la siguiente palabra. \n",
        "\n",
        "En la letra del laboratorio se menciona que este algoritmo es intensivo en CPU, es parte de la consigna del laboratorio implementar el algoritmo de la manera más eficiente posible.\n",
        "\n",
        "Detectamos las siguientes tareas para cumplir con la consigna:\n",
        "\n",
        "- **Definir las estructuras de datos**: Debemos diseñar las estructuras de datos que nos permitan almacenar la información necesaria para el funcionamiento del algoritmo. De forma tal que el acceso a la información y los calculos sean lo más eficientes posibles.\n",
        "- **Modulo auxiliar `naive_bayes_utils.py`**: Una vez diseñadas las estructuras de datos, debemos implementarlas, proponemos hacerlo siguiendo un enfoque modular, donde se plasmen las ideas discutidas en el punto anterior.\n",
        "- **Clase `G02NaiveBayesClassifier`**: Una vez implementadas las estructuras de datos, debemos implementar la clase `G02NaiveBayesClassifier` que encapsula el algoritmo de clasificación y mantiene todo el aparato auxiliar encapsulado bajo la misma clase. Esta clase será definida en el modulo `bayesian_learning.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Definir las estructuras de datos\n",
        "\n",
        "Nuestro modelo busca sugerir la palabra más probable dado un contexto de N palabras anteriores. Esto es coincidente con el objetivo mas general de los clasificadores bayesianos, que es encontrar la hipótesis más probable dado un conjunto de evidencias. (`h_map`)\n",
        "\n",
        "- `h_map` = argmax<sub>h</sub> P(h|D) = argmax<sub>h</sub> P(D|h) P(h) / P(D)\n",
        "\n",
        "Los clasificadores bayesianos naive asumen que las evidencias son independientes entre si, por lo que la probabilidad de la hipótesis MAP se puede expresar como el producto de las probabilidades de cada evidencia dada la hipótesis multiplicado por la probabilidad de la hipótesis.\n",
        "\n",
        "- `h_map` = argmax<sub>h</sub> P(D|h) P(h) / P(D) = argmax<sub>h</sub> P(D|h) P(h) = argmax<sub>h</sub> P(d<sub>1</sub>|h) ... P(d<sub>n</sub>|h) P(h)\n",
        "\n",
        "Nuestro meta-parámetro `N` indica la cantidad de palabras anteriores a considerar para la predicción de la siguiente palabra. Es decir, `N` es la cantidad de evidencias que consideramos para calcular la probabilidad de la hipótesis (la palabra a sugerir).\n",
        "\n",
        "Si bien un modelo bayesiano naive simplifica los calculos, diseñar estructuras de datos y algoritmos eficientes para calcular las probabilidades no es trivial. Proponemos las siguientes estructuras de datos para almacenar la información necesaria para el funcionamiento del algoritmo:\n",
        "\n",
        "- `V`: Vocabulario de palabras en el conjunto de entrenamiento.\n",
        "- `F_h`: Frecuencia de cada hipótesis (palabra) en el conjunto de entrenamiento.\n",
        "- `F_hD`: Frecuencia de cada evidencia (palabra anterior) dado una hipótesis (palabra) en el conjunto de entrenamiento. A diferencia de `F_h`, `F_hD` es un diccionario de diccionarios y es afectado por el meta-parámetro `N`, ya que la cantidad de evidencias a considerar depende de `N`. Por ejemplo, si `N=4` y la hipótesis es `h`, `F_hD[h]` es un diccionario que contiene la frecuencia de cada combinación de 4 palabras anteriores a `h` en el conjunto de entrenamiento. Esto implica tambien que las frases de longitud menor a `N` no aportan información para el entrenamiento del modelo.\n",
        "\n",
        "Para calcular las probabilidades usamos el m-estimador como estimador de máxima verosimilitud y suavizador de hipotesis que no aparecen en el conjunto de entrenamiento hasta el momento de la predicción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modulo auxiliar `naive_bayes_utils.py`\n",
        "\n",
        "El modulo `naive_bayes_utils.py` encapsula las estructuras de datos y los algoritmos auxiliares necesarios para el funcionamiento del clasificador bayesiano naive. \n",
        "\n",
        "Estas estructuras de datos fueron definidas en el punto anterior y fueron implementadas en el modulo `naive_bayes_utils.py` de la siguiente manera:\n",
        "\n",
        "- `count_words(**args)`: Esta función recibe los datos de entrenamiento preprocesados y el meta-parámetro `N` y devuelve las estructuras de datos `V`, `F_h` y `F_hD` definidas anteriormente.\n",
        "- `p_h(**args)`: Esta función recibe las estructuras de datos `V`, `F_h` y `F_hD` y `m` y devuelve un estimador de máxima verosimilitud de la probabilidad de cada hipótesis (palabra) en el conjunto de entrenamiento.\n",
        "- `p_hD(**args)`: Esta función recibe las estructuras de datos `V`, `F_h` y `F_hD` y `m` y devuelve un estimador de máxima verosimilitud de la probabilidad de cada evidencia (palabra anterior) dado una hipótesis (palabra) en el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.naive_bayes_utils import *\n",
        "\n",
        "V, F_h, F_hD = build(preprocessed_data, N= 1)\n",
        "\n",
        "results = {\n",
        "    'V': V,\n",
        "    'F_h': F_h,\n",
        "    'F_hD': F_hD,\n",
        "    'P(h)': p_h('hoy', V, F_h),\n",
        "    'P(di|h)': p_hD('disponibles', 'hoy', V, F_h, F_hD)\n",
        "}\n",
        "\n",
        "for key, value in results.items():\n",
        "  print(f'{key}: {value}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clase `G02NaiveBayesClassifier`\n",
        "\n",
        "La clase `G02NaiveBayesClassifier` es una implementación de un clasificador Naive Bayes. Aquí hay un resumen de sus componentes principales:\n",
        "\n",
        "- `__init__`: El constructor toma un conjunto de datos y un parámetro `N` que indica cuántas palabras anteriores se deben considerar para la predicción. El constructor también inicializa el preprocesador y construye las estructuras de datos necesarias (`V`, `F_h`, `F_hD`) utilizando la función `build`.\n",
        "\n",
        "- `predict`: Esta función toma una oración y devuelve la palabra más probable según el modelo Naive Bayes. Utiliza el logaritmo de las probabilidades para evitar problemas de precisión numérica.\n",
        "\n",
        "- `update`: Esta función actualiza el modelo con una nueva oración. Actualiza las frecuencias de las palabras y las frecuencias condicionales, así como el tamaño total del vocabulario (`V`).\n",
        "\n",
        "La clase utiliza funciones auxiliares como `p_h` y `p_hD`, definidas en el módulo `naive_bayes_utils.py`, para calcular las probabilidades de las palabras.\n",
        "\n",
        "```python\n",
        "def predict(self, sentence):\n",
        "    argmax_h = {}\n",
        "\n",
        "    for h in self.F_h.keys():\n",
        "        p = log(p_h(h, self.V, self.F_h))\n",
        "\n",
        "        for word in sentence:\n",
        "            p += log(p_hD(word, h, self.V, self.F_h, self.F_hD))\n",
        "\n",
        "        argmax_h[h] = p\n",
        "    \n",
        "    return max(argmax_h, key=argmax_h.get)\n",
        "    \n",
        "def update(self, new_sentence):\n",
        "    self.F_h.update(new_sentence)\n",
        "\n",
        "    for i in range(self.N, len(new_sentence)):\n",
        "        current_word = new_sentence[i]\n",
        "        previous_words = tuple(new_sentence[i-self.N:i])\n",
        "\n",
        "        for previous_word in previous_words:\n",
        "            self.F_hD[current_word].update([previous_word])\n",
        "    \n",
        "    self.V = sum(self.F_h.values())\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.bayesian_learning import G02NaiveBayesClassifier\n",
        "import time\n",
        "\n",
        "clf = G02NaiveBayesClassifier(data, N=1)\n",
        "test = ['ejemplo']\n",
        "\n",
        "print(' '.join(test))\n",
        "\n",
        "start = time.time()\n",
        "for i in range(2): test.append(clf.predict(test))\n",
        "print(f'[PREDICT] Tiempo de ejecución: {time.time() - start:.4f}s')\n",
        "\n",
        "print(f'        V: {clf.V} \\\n",
        "    \\n          F_h[{test[1]}]: {clf.F_h[test[1]]} \\\n",
        "    \\n          F_hD[{test[1]}][{test[0]}]: {clf.F_hD[test[1]][test[0]]} \\\n",
        "    \\n          F_h[{test[2]}]: {clf.F_h[test[2]]} \\\n",
        "    \\n          F_hD[{test[2]}][{test[1]}]: {clf.F_hD[test[2]][test[1]]}')\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "print(' '.join(test))\n",
        "\n",
        "clf.update(test)\n",
        "print(f'[UPDATE]  Tiempo de ejecución: {time.time() - start:.4f}s')\n",
        "\n",
        "print(f'        V: {clf.V} \\\n",
        "    \\n          F_h[{test[1]}]: {clf.F_h[test[1]]} \\\n",
        "    \\n          F_hD[{test[1]}][{test[0]}]: {clf.F_hD[test[1]][test[0]]} \\\n",
        "    \\n          F_h[{test[2]}]: {clf.F_h[test[2]]} \\\n",
        "    \\n          F_hD[{test[2]}][{test[1]}]: {clf.F_hD[test[2]][test[1]]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluación\n",
        "\n",
        "En cualquier laboratorio o proyecto de investigación, la sección de evaluación es crucial para entender cómo se mide el rendimiento del modelo y qué métricas son relevantes para el problema en cuestión. Sin embargo, la naturaleza planteada en la letra del laboratorio no permite una evaluación cuantitativa del modelo. Por lo tanto, proponemos una evaluación cualitativa del modelo.\n",
        "\n",
        "No sabemos como cuantificar el hecho de que el modelo esta \"sugeriendo bien\" dado que es una percepción subjetiva del usuario que esta manteniendo una conversación con el modelo.\n",
        "\n",
        "Lo que si podemos hacer, adoptando una evaluacion ya mas relajada. Dada una sesion de cliente, cuantificar la cantidad de veces que el modelo sugiere una palabra que el usuario considera correcta.\n",
        "\n",
        "Alterando el tamaño de la ventana de palabras `N`, y el suavizado `M` buscamos encontrar un equilibrio entre las siguientes propiedades deseables:\n",
        "\n",
        "- **Memoria**: El modelo debe ser capaz de sugerir palabras que tengan coherencia con el grupo de Whatsapp de donde se extrajeron los datos.\n",
        "\n",
        "- **Adaptacion**: El modelo debe ser capaz de adaptarse a la nueva evidencia, y mejorar su performance, sugiriendo palabras que tengan coherencia con la sesion de chat que se esta simulando.\n",
        "\n",
        "Esta particularidad en la evaluación del modelo, tambien impacta en la definición de los conjuntos de entrenamiento, prueba y evaluación.\n",
        "\n",
        "El clasificador bayesiano se construye a partir de un conjunto de entrenamiento. En nuestro caso, el conjunto de entrenamiento es el conjunto de mensajes de un grupo de WhatsApp. No hay conjunto de prueba ni conjunto de evaluación. El modelo se evalúa en tiempo real, mientras el usuario (en primera instancia nosotros y luego el cuerpo docente) interactúa con el modelo y evalúa la calidad de las sugerencias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimentación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simulador de cliente.\n",
        "\n",
        "El experimento consiste en evaluar los distintos hiperparametros del modelo.\n",
        "\n",
        "El siguiente script permite simular el comportamiento de un cliente que escribe frases, fue proporcionado por el cuerpo docente. Es de utilidad para experimentar con modelo, ya que permite ingresar frases y ver las sugerencias que el modelo realiza.\n",
        "\n",
        "**Nota:**\n",
        "\n",
        "El comportamiento del siguiente script en `VSCode` es diferente al comportamiento en la terminal. En VSCode, el script omite entradas, se desfasa y hace que el analisis de los resultados sea dificil. Por lo tanto, recomendamos ejecutar el script en la terminal. (`client.py`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
        "- ¿cuándo se dieron los mejores resultados del jugador?\n",
        "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
        "- ¿cómo mejoraría los resultados?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
