{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrega 2, Grupo 02 - Aprendizaje Bayesiano\n",
        "\n",
        "- Santiago Alaniz,  5082647-6, santiago.alaniz@fing.edu.uy\n",
        "- Bruno De Simone,  4914555-0, bruno.de.simone@fing.edu.uy\n",
        "- María Usuca,      4891124-3, maria.usuca@fing.edu.uy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementar un algoritmo de predicción de palabras utilizando Naive Bayes. El modelo se entrenará con datos de conversaciones de WhatsApp y se probará en un simulador de cliente. \n",
        "\n",
        "El algoritmo debe ser capaz de recomendar palabras basadas en las últimas N palabras ingresadas en una frase, donde N es un hiperparámetro que se variará para evaluar el desempeño del modelo. Además, el modelo se reentrenará al finalizar cada frase para adaptarse a nueva evidencia. \n",
        "\n",
        "La implementación debe ser eficiente en términos de uso de CPU, utilizando las estructuras de datos más adecuadas en Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diseño"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carga del dump de conversaciones en un grupo de WhatsApp\n",
        "\n",
        "En la letra del laboratorio se menciona que se puede acceder al dump en formato `.csv` pero esto es un error en la letra. *WhatsApp* exporta las conversaciones en formato `.txt`.\n",
        "\n",
        "Esto complejiza la carga de los datos ya que no podemos asumir que cada linea del archivo es una entrada del log.\n",
        "\n",
        "Detectamos el siguiente patron en el archivo de texto\n",
        "\n",
        "```\n",
        "  [dd/mm/aaaa hh:mm:ss] <nombre>: <mensaje>\n",
        "    ***\n",
        "  [dd/mm/aaaa hh:mm:ss] <nombre>: <mensaje>\n",
        "```\n",
        "\n",
        "Nos valemos del modulo `src.regex` para definir la expresion regular que detecta el patron y extrae los mensajes (`LOG_ENTRY_PATTERN`).\n",
        "\n",
        "`LOG_ENTRY_PATTERN = f'{metadata_pattern}{message_pattern}(?=\\n{metadata_pattern}|$)':`\n",
        "\n",
        "Esta expresion regular captura el contenido de cada entrada del log en dos grupos: `metadata` y `message`. \n",
        "\n",
        "- El grupo `metadata` captura la fecha y hora de la entrada, el nombre del usuario o el numero de telefono. \n",
        "- El grupo `message` captura el mensaje en si mismo y es el que nos interesa recuperar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from src.regex import LOG_ENTRY_PATTERN\n",
        "\n",
        "FILE_PATH = './assets/chat.txt'\n",
        "PATTERN = LOG_ENTRY_PATTERN\n",
        "\n",
        "with open(FILE_PATH, 'r', encoding='utf-8') as file:\n",
        "  chat = file.read()\n",
        "\n",
        "matches = re.findall(PATTERN, chat)\n",
        "data = [ match[1] for match in matches ]\n",
        "\n",
        "print(f'Cantidad de mensajes: {len(data)}')\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesamiento de datos\n",
        "\n",
        "Para un algoritmo de sugerencia de palabras basado en aprendizaje bayesiano, el preprocesamiento de los datos es crucial para obtener resultados significativos. En nuestro caso, se compone de los siguientes pasos:\n",
        "\n",
        "1. **Conversión a minúsculas**: Para que el algoritmo no trate las palabras como diferentes solo debido a las diferencias de mayúsculas y minúsculas.\n",
        "2. **Eliminación de caracteres especiales, numericos, emojis**: Estos componentes lexicos y semanticos no aportan información relevante para el modelo que busca sugerir palabras.\n",
        "3. **Eliminación de [stopwords](https://es.wikipedia.org/wiki/Palabra_vac%C3%ADa)**: Estas palabras aparecen con mucha frecuencia en el lenguaje natural independientemente del contexto, por lo que no aportan información relevante para el modelo.\n",
        "4. **Tokenización ordenada**: Para que el algoritmo pueda identificar correctamente las palabras y su posición en la oración, es necesario dividir la oración en [tokens](https://es.wikipedia.org/wiki/Token).\n",
        "5. **Cruzamiento de palabras con un [corpus](http://universal.elra.info/product_info.php?cPath=42_43&products_id=1509)**: Para descartar palabras que no pertenecen al idioma español, chequeamos su existencia en un [corpus](https://es.wikipedia.org/wiki/Corpus_ling%C3%BC%C3%ADstico). Esto es importante para evitar que el modelo sugiera palabras en otros idiomas o palabras que no existen.\n",
        "6. **Relajar tildes**: Para que el modelo no distinga palabras con tildes de palabras sin tildes. Teniendo en cuenta que en los mensajes de WhatsApp es muy común que se omitan las tildes.\n",
        "\n",
        "Construimos la clase `src.G02Preprocessor` para encapsular el preprocesamiento de los datos y realizar los pasos mencionados anteriormente con mayor facilidad y control.\n",
        "\n",
        "*Nota:* \n",
        "\n",
        "La lista resultado del preprocesamiento tiene un tamaño menor a la lista original. Esto se debe a que el preprocesamiento puede descartar mensajes que no cumplen con los criterios de preprocesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.preprocessing import G02Preprocessor\n",
        "\n",
        "preprocessor = G02Preprocessor()\n",
        "preprocessed_data = preprocessor.apply(data)\n",
        "\n",
        "print(f'Cantidad de mensajes post preprocesamiento: {len(preprocessed_data)}')\n",
        "preprocessed_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from collections import Counter\n",
        "\n",
        "TXT_PATH = './assets/chat.txt'\n",
        "\n",
        "nltk.download('words')\n",
        "spanish_words = set(words.words())\n",
        "\n",
        "with open(TXT_PATH, 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "filtered_content = [line.split(':', 2)[-1].strip() for line in lines]\n",
        "all_words = ' '.join(filtered_content).split()\n",
        "all_words_lower = [word.lower() for word in all_words]\n",
        "\n",
        "\n",
        "filtered_words = [word for word in all_words_lower if word in spanish_words]\n",
        "\n",
        "word_count = Counter(filtered_words)\n",
        "sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for word, frequency in sorted_words:\n",
        "    print(f\"{word}: {frequency}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Opcion usando un txt como diccionario. (en nltk no estan todas las palabras, por ejemplo, pollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Algoritmo\n",
        "Extensiones del algoritmo original necesarias para la resolución del problema: tratamiento de atributos faltantes, numéricos, etc. (si es el propio algoritmo el que lo maneja), implementaciones adicionales necesarias para manejar ensambles de clasificadores, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluación\n",
        "- Qué conjunto de métricas se utilizan para la evaluación de la solución y su definición\n",
        "- Sobre qué conjunto(s) se realiza el entrenamiento, ajuste de la solución, evaluación, etc. Explicar cómo se construyen estos conjuntos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimentación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simulador de cliente.\n",
        "\n",
        "El experimento consiste en evaluar los distintos hiperparametros del modelo. Alterando el tamaño de la ventana de palabras, y el vocabulario buscamos encontrar un equilibrio entre las siguientes propiedades deseables:\n",
        "\n",
        "- **Memoria**: El modelo debe ser capaz de sugerir palabras que tengan coherencia con el grupo de Whatsapp de donde se extrajeron los datos.\n",
        "\n",
        "- **Adaptacion**: El modelo debe ser capaz de adaptarse a la nueva evidencia, y mejorar su performance, sugiriendo palabras que tengan coherencia con la sesion de chat que se esta simulando.\n",
        "\n",
        "El siguiente script permite simular el comportamiento de un cliente que escribe frases, fue proporcionado por el cuerpo docente. Es de utilidad para evaluar el desempeño del modelo, ya que permite ingresar frases y ver las sugerencias que el modelo realiza.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrHEaPPcj30i",
        "outputId": "33cfb55d-d899-4720-c22b-71dfe9f51303"
      },
      "outputs": [],
      "source": [
        "def recomendacion_bayesiana(frase):\n",
        "  import random\n",
        "\n",
        "  dias = [\"Lunes\", \"Martes\", \"Miércoles\", \"Jueves\", \"Viernes\", \"Sábado\", \"Domingo\"]\n",
        "\n",
        "  # ## PSEUDOCODIGO - pag 55 - diapo##\n",
        "\n",
        "  # D = [\"mi\", \"hijo\", \"se\", \"olvidó\", \"de\", \"la\"]\n",
        "  # Horizonte = 4 #hiperparametro\n",
        "  # h_MAP = \"\"\n",
        "  # p_MAP = 0\n",
        "  # for h in P:\n",
        "    \n",
        "  #   prob = P[h]\n",
        "    \n",
        "  #   for d in D[-Horizonte:]:\n",
        "  #     prob = prob * PD[h].get(d, P_nada) \n",
        "  #     #P_nada es un valor que debemos definir para el caso cuando la palabra no se encuentre en el listado\n",
        "    \n",
        "  #   if prob > p_MAP:\n",
        "  #     h_MAP , p_MAP = h , prob\n",
        "  # print(h_MAP)\n",
        "\n",
        "  return(random.choice(dias))\n",
        "\n",
        "\n",
        "##### LOOP PRINCIPAL #####\n",
        "\n",
        "print(\"Ingrese la frase dando ENTER luego de \\x1b[3mcada palabra\\x1b[0m.\")\n",
        "print(\"Ingrese sólo ENTER para aceptar la recomendación sugerida\")\n",
        "print(\"Ingrese '.' para comenzar con una frase nueva.\")\n",
        "print(\"Ingrese '..' para terminar el proceso.\")\n",
        "\n",
        "frase = []\n",
        "palabra_sugerida = \"\"\n",
        "\n",
        "while 1:\n",
        "  palabra = input(\">> \")\n",
        "\n",
        "  if palabra == \"..\":\n",
        "    break\n",
        "\n",
        "  elif palabra == \".\":\n",
        "    print(\"----- Comenzando frase nueva -----\")\n",
        "    frase = []\n",
        "\n",
        "  elif palabra == \"\": # acepta última palabra sugerida\n",
        "    frase.append(palabra_sugerida)\n",
        "\n",
        "  else: # escribió una palabra\n",
        "    frase.append(palabra)\n",
        "\n",
        "  if frase:\n",
        "    palabra_sugerida = recomendacion_bayesiana(frase)\n",
        "\n",
        "    frase_propuesta = frase.copy()\n",
        "    frase_propuesta.append(\"\\x1b[3m\"+ palabra_sugerida +\"\\x1b[0m\")\n",
        "\n",
        "    print(\" \".join(frase_propuesta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
        "- ¿cuándo se dieron los mejores resultados del jugador?\n",
        "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
        "- ¿cómo mejoraría los resultados?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
