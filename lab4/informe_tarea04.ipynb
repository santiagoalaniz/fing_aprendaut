{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 4 - Redes Neuronales\n",
    "\n",
    "**Grupo 02:**\n",
    "\n",
    "| Nombre         | C.I       | Email                        |\n",
    "|----------------|-----------|------------------------------|\n",
    "| Santiago Alaniz| 5082647-6 | santiago.alaniz@fing.edu.uy  |\n",
    "| Bruno De Simone| 4914555-0 | bruno.de.simone@fing.edu.uy  |\n",
    "| María Usuca    | 4891124-3 | maria.usuca@fing.edu.uy      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Considere **[Fashion-MNIST1](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion)**, un conjunto de datos con imágenes de 10 tipos diferentes de artículos de la empresa de vestimenta Zalando.\n",
    "\n",
    "Este laboratorio busca desarrollar y optimizar un clasificador basado en redes neuronales para el dataset `Fashion-MNIST` de Zalando. Inicialmente, se establecerá una arquitectura base de red neuronal feedforward con parámetros específicos.\n",
    "\n",
    "Posteriormente, se experimentará con tres arquitecturas adicionales para mejorar la clasificación. Al identificar el modelo más prometedor, se aplicarán técnicas de regularización y se comparará su rendimiento con benchmarks existentes. \n",
    "\n",
    "Finalmente, se identificarán las imágenes más desafiantes para el clasificador. \n",
    "\n",
    "Todo el desarrollo se realizará utilizando `PyTorch`, los resultados y análisis se presentarán en esta Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Al dia de la fecha, dada la popularidad del dataset, muchas librerias han incorporado la carga de `Fashion-MNIST` como parte de su API.\n",
    "\n",
    "`PyTorch` no es la excepción, la incluye en su libreria para datasets de visión artificial `torchvision`.\n",
    "\n",
    "Particionamos los datos en dos conjuntos con `torch.utils.data.random_split` de la siguiente manera:\n",
    "\n",
    "- `train` para entrenar el modelo.\n",
    "- `eval` para evaluar el modelo.\n",
    "- `test` para evaluar el modelo final.\n",
    "\n",
    "Ademas, por cuestiones de reproducibilidad, se particiona el conjunto de entrenamiento en `train` y `val` con un generador determinado por una semilla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Diseño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "TEST_SIZE = 0.5\n",
    "SEED_NUMBER = 42069\n",
    "\n",
    "train = datasets.FashionMNIST('./data', train=True, download=True, transform= ToTensor())\n",
    "test = datasets.FashionMNIST('./data', train=False, download=True, transform= ToTensor())\n",
    "\n",
    "deterministic_generator = torch.Generator()\n",
    "deterministic_generator.manual_seed(SEED_NUMBER)\n",
    "\n",
    "test, eval = torch.utils.data.random_split(\n",
    "    test, \n",
    "    [int(len(test) * (1-TEST_SIZE)), int(len(test) * TEST_SIZE)],\n",
    "    generator=deterministic_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LABELS = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train), size=(1,)).item()\n",
    "    img, label = train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(LABELS[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos\n",
    "\n",
    "Para este laboratorio optamos por no relizar nosotros mismos el preprocesamiento, sino valernos de las herramientas que provee `Pytorch`. En particular [DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) nos permite preparar los datos para el entrenamiento de la red neuronal.\n",
    "\n",
    "`DataLoader` actua como [wrapper](https://en.wikipedia.org/wiki/Wrapper_function)  de un dataset, permitiendo iterar sobre el mismo en batches de tamaño configurable. Además, permite realizar transformaciones sobre los datos, en nuestro caso, transformamos las imagenes a tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE)\n",
    "eval_dataloader = DataLoader(eval, batch_size=BATCH_SIZE)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Algoritmo\n",
    "\n",
    "Definimos la clase `NeuralNetwork` como una subclase de [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). La clase `NeuralNetwork` define la arquitectura de la red neuronal, y la clase Module de PyTorch nos permite utilizar la red neuronal definida en la clase NeuralNetwork para entrenarla y realizar predicciones. \n",
    "\n",
    "La arquitectura de la red neuronal es la siguiente:\n",
    "\n",
    "* Capa de entrada (`fc1`): es una capa completamente conectada (o densa) que transforma la entrada de 784 (28*28) dimensiones a una representación intermedia de 32 dimensiones. \n",
    "\n",
    "* Capa oculta (`sigmoide`): esta capa utiliza la función sigmoide como función de activación.\n",
    "\n",
    "* Capa de salida (`fc2`): hay 10 clases diferentes en el conjunto de datos Fashion-MNIST, por lo tanto, la capa de salida tiene 10 neuronas, una para cada clase.\n",
    "\n",
    "En `PyTorch`, el concepto de `device` permite que los calculos se realicen en una CPU o GPU (si está disponible). Esto puede generar problemas dado que los tensores deben estar en el mismo dispositivo para poder operar con ellos. Por ejemplo, el conjunto de datos puede estar en la CPU, mientras que el modelo puede estar en la GPU. Para evitar este problema, se utiliza la función `to(DEVICE)` para mover los tensores a un dispositivo dado.\n",
    "\n",
    "***Nota***\n",
    "\n",
    "Una estrategia interesante en el caso de modelo(gpu) y datos(cpu) es agregar el argumento `pin_memory=True` al constructor de la clase `DataLoader`. Esto acelara la transmición de datos entre dispositivos, dado que se fijan las páginas de memoria en la RAM destinadas al almacenamiento de los datos. Este acercamiento asegura una transmición más rápida, pero utiliza más memoria RAM.\n",
    "\n",
    "Lamentablemente, la clase `DataLoader` no permite cargar todos los datos directamente en la GPU, por lo que se debe utilizar el argumento `pin_memory=True` y luego mover los batches de datos a la GPU con `to(DEVICE)`.\n",
    "\n",
    "Esto tiene sentido dado que la GPU tiene una memoria mucho más limitada que la RAM, en nuestro Fashion-MNIST cabe en una GPU moderna, pero obviamente no es el caso para datasets más grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_network import *\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "model = NeuralNetwork().to(DEVICE)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener el primer lote del DataLoader\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "# Tomar la primera imagen y etiqueta del lote\n",
    "single_image = images[0]\n",
    "single_label = labels[0]\n",
    "\n",
    "# Visualizar la imagen\n",
    "plt.imshow(single_image[0].numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Etiqueta: {LABELS[single_label.item()]}\")\n",
    "plt.show()\n",
    "\n",
    "single_image = single_image.to(DEVICE) \n",
    "# Pasar la imagen a través del modelo\n",
    "output = model(single_image)\n",
    "prediction = torch.argmax(output, dim=1)\n",
    "\n",
    "print(f\"Predicción del modelo: {LABELS[prediction.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "- ii) Utilizando el conjunto de entrenamiento provisto, entrene a la red construida en el paso anterior durante 10 épocas\n",
    "- iii) Evalúe el rendimiento del clasificador construido sobre un conjunto de validación, utilizando descenso por gradiente estocástico y una tasa de aprendizaje de 0.01.\n",
    "- iv) Reporte gráficamente la evolución de la pérdida en el conjunto de entrenamiento y de la accuracy sobre el conjunto de validación en función de las iteraciones.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la red neuronal durante 10 épocas con el conjunto `train`, y evaluamos el rendimiento del clasificador sobre el conjunto `eval`. \n",
    "\n",
    "Para el entrenamiento utilizamos la función de pérdida de entropía cruzada, ya que es una buena opción para problemas de clasificación multiclase. Y se usa el descenso por gradiente estocástico (SGD) como nuestro optimizador, con una tasa de aprendizaje de 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_and_test import train_model, test_model\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "train_accuracies = []\n",
    "eval_accuracies = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}:\")\n",
    "    \n",
    "    train_loss, train_acc = train_model(train_dataloader, model, loss_fn, optimizer, DEVICE)\n",
    "    eval_loss, eval_acc = test_model(eval_dataloader, model, loss_fn, DEVICE)\n",
    "    \n",
    "    print(f\"Train loss {train_loss}, Eval loss {eval_loss}, Train accuracy {train_acc}, Eval accuracy {eval_acc}\\n-------------------------------\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    eval_losses.append(eval_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    eval_accuracies.append(eval_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra la evolución de la pérdida en el conjunto de entrenamiento y de la accuracy sobre el conjunto de validación en función de las iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Entrenamiento', color='tab:red')\n",
    "plt.plot(eval_losses, label='Validación', color='tab:orange')\n",
    "plt.title('Evolución de la perdida')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perdida')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Entrenamiento', color='tab:red')\n",
    "plt.plot(eval_accuracies, label='Validación', color='tab:blue')\n",
    "plt.title('Evolución de la precisión')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión (%)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar una mejora en la precisión y una disminución en la pérdida a medida que avanzan las épocas. Esto indica que el modelo está aprendiendo a clasificar mejor las imágenes de Fashion-MNIST.\n",
    "\n",
    "El modelo alcanzó una precisión del 76,68% sobre el conjunto de validación. Lo cual es un buen resultado para un modelo base, este desempeño establece un punto de referencia para comparar con los modelos de los siguientes puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación\n",
    "\n",
    "```\n",
    "b) Proponga tres arquitecturas adicionales que busquen mejorar los resultados, modificando la cantidad de unidades, la cantidad de capas ocultas, y/o diferentes funciones de activación. Para cada una, evalúe su rendimiento sobre un conjunto de validación, con diferentes valores de tasa de aprendizaje. \n",
    "\n",
    "c) A partir del mejor modelo obtenido en b), sugiera y aplique algún mecanimo de regularización y vuelva a evaluar sobre el conjunto de validación, igual que en el paso anterior.\n",
    "\n",
    "d) Con el mejor modelo obtenido luego de los pasos anteriores, evalúe su performance sobre el conjunto de evaluación utilizando accuracy, precision, recall y medida F1 para cada una de las clases. \n",
    "\n",
    "Construya la matriz de confusión. Comente los resultados y compare con los reportados en el sitio del dataset. \n",
    "\n",
    "e) Muestre las diez instancias del conjunto de evaluación más “difíciles” para el clasificador construido, utilizando como medida la entropía. Comente los resultados.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir tres arquitecturas adicionales:\n",
    "\n",
    "**Arquitectura 1** \n",
    "\n",
    "`NeuralNetwork1` es una red neuronal con dos capas ocultas, la primera con 64 unidades y la segunda con 32 unidades. Ambas capas utilizan la función sigmoide como función de activación. \n",
    "\n",
    "* Propuesta: aumentar la complejidad del modelo para mejorar la precisión, agregando más unidades y capas ocultas, para que el modelo pueda aprender patrones más complejos.\n",
    "\n",
    "**Arquitectura 2**\n",
    "\n",
    "`NeuralNetwork2` es una red neuronal con una capa oculta de 64 unidades que utiliza la función sigmoide como función de activación.\n",
    "\n",
    "* Propuesta: Reducir la complejidad al tener una única capa oculta puede ayudar a evitar el sobreajuste y a mejorar la convergencia en conjuntos de datos más pequeños.\n",
    "  \n",
    "**Arquitectura 3**\n",
    "\n",
    "`NeuralNetwork3` es una red neuronal con una capa oculta de 32 unidades que utiliza la funcion ReLU como función de activación. \n",
    "\n",
    "* Propuesta: Ver los resultados al cambiar la función de activación de la capa oculta a ReLU, ya que es una función de activación más moderna y que suele dar buenos resultados.\n",
    "\n",
    "En cada caso, se evalúa el rendimiento del clasificador sobre el conjunto de validación, utilizando diferentes valores de tasa de aprendizaje. Los resultados de estas evaluaciones se utilizarán para seleccionar la mejor arquitectura y parámetros de entrenamiento para nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_network import *\n",
    "from src.neural_network_1 import *\n",
    "from src.neural_network_2 import *\n",
    "\n",
    "model1 = NeuralNetwork1().to(DEVICE)\n",
    "print (model1)\n",
    "model2 = NeuralNetwork2().to(DEVICE)\n",
    "print (model2)\n",
    "model = NeuralNetwork().to(DEVICE)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_and_test import train_and_evaluate, plot_results\n",
    "import pandas as pd\n",
    "TASA_APRENDIZAJE = 0.01\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=TASA_APRENDIZAJE)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "results = train_and_evaluate(epochs, loss_fn, optimizer, model1, train_dataloader, eval_dataloader,  DEVICE)\n",
    "plot_results(results)\n",
    "results.to_csv('data/model1.csv', index=False)   \n",
    "results = train_and_evaluate(epochs, loss_fn, optimizer, model2, train_dataloader, eval_dataloader,  DEVICE)\n",
    "plot_results(results)\n",
    "results.to_csv('data/model2.csv', index=False)  \n",
    "results = train_and_evaluate(epochs, loss_fn, optimizer, model, train_dataloader, eval_dataloader, DEVICE)\n",
    "plot_results(results)\n",
    "results.to_csv('data/model.csv', index=False)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia.\n",
    "\n",
    "- [Tutorial de PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "- [Fashion-MNIST1](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
