{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 4 - Redes Neuronales\n",
    "\n",
    "**Grupo 02:**\n",
    "\n",
    "| Nombre         | C.I       | Email                        |\n",
    "|----------------|-----------|------------------------------|\n",
    "| Santiago Alaniz| 5082647-6 | santiago.alaniz@fing.edu.uy  |\n",
    "| Bruno De Simone| 4914555-0 | bruno.de.simone@fing.edu.uy  |\n",
    "| María Usuca    | 4891124-3 | maria.usuca@fing.edu.uy      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Considere **[Fashion-MNIST1](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion)**, un conjunto de datos con imágenes de 10 tipos diferentes de artículos de la empresa de vestimenta Zalando.\n",
    "\n",
    "Este laboratorio busca desarrollar y optimizar un clasificador basado en redes neuronales para el dataset `Fashion-MNIST` de Zalando. Inicialmente, se establecerá una arquitectura base de red neuronal feedforward con parámetros específicos.\n",
    "\n",
    "Posteriormente, se experimentará con tres arquitecturas adicionales para mejorar la clasificación. Al identificar el modelo más prometedor, se aplicarán técnicas de regularización y se comparará su rendimiento con benchmarks existentes. \n",
    "\n",
    "Finalmente, se identificarán las imágenes más desafiantes para el clasificador. \n",
    "\n",
    "Todo el desarrollo se realizará utilizando `PyTorch`, los resultados y análisis se presentarán en esta Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Al día de la fecha, dada la popularidad del dataset, muchas librerías han incorporado la carga de `Fashion-MNIST` como parte de su API.\n",
    "\n",
    "`PyTorch` no es la excepción, la incluye en su librería para datasets de visión artificial `torchvision`.\n",
    "\n",
    "Particionamos los datos en dos conjuntos con `torch.utils.data.random_split` de la siguiente manera:\n",
    "\n",
    "- `train` para entrenar el modelo.\n",
    "- `eval` para evaluar el modelo.\n",
    "- `test` para evaluar el modelo final.\n",
    "\n",
    "Además, por cuestiones de reproducibilidad, se particiona el conjunto de entrenamiento en `train` y `val` con un generador determinado por una semilla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Diseño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "TEST_SIZE = 0.5\n",
    "SEED_NUMBER = 42069\n",
    "\n",
    "train = datasets.FashionMNIST('./data', train=True, download=True, transform= ToTensor())\n",
    "test = datasets.FashionMNIST('./data', train=False, download=True, transform= ToTensor())\n",
    "\n",
    "deterministic_generator = torch.Generator()\n",
    "deterministic_generator.manual_seed(SEED_NUMBER)\n",
    "\n",
    "test, eval = torch.utils.data.random_split(\n",
    "    test, \n",
    "    [int(len(test) * (1-TEST_SIZE)), int(len(test) * TEST_SIZE)],\n",
    "    generator=deterministic_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LABELS = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train), size=(1,)).item()\n",
    "    img, label = train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(LABELS[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos\n",
    "\n",
    "Para este laboratorio optamos por no realizar nosotros mismos el preprocesamiento, sino valernos de las herramientas que provee `Pytorch`. En particular [DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) nos permite preparar los datos para el entrenamiento de la red neuronal.\n",
    "\n",
    "`DataLoader` actúa como [wrapper](https://en.wikipedia.org/wiki/Wrapper_function)  de un dataset, permitiendo iterar sobre el mismo en batches de tamaño configurable. Además, permite realizar transformaciones sobre los datos, en nuestro caso, transformamos las imágenes a tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE)\n",
    "eval_dataloader = DataLoader(eval, batch_size=BATCH_SIZE)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "Definimos la clase `NeuralNetwork` como una subclase de [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). La clase `NeuralNetwork` define la arquitectura de la red neuronal, y la clase Module de PyTorch nos permite utilizar la red neuronal definida en la clase NeuralNetwork para entrenar y realizar predicciones. \n",
    "\n",
    "La arquitectura de la red neuronal es la siguiente:\n",
    "\n",
    "* Capa de entrada (`fc1`): es una capa completamente conectada (o densa) que transforma la entrada de 784 (28*28) dimensiones a una representación intermedia de 32 dimensiones. \n",
    "\n",
    "* Capa oculta (`sigmoide`): esta capa utiliza la función sigmoide como función de activación.\n",
    "<br>\n",
    "  <p align=\"center\">\n",
    "    <img width=\"400\" src=\"img/SigmoidFunction.svg\"/>\n",
    "  </p>\n",
    "<br>\n",
    "\n",
    "* Capa de salida (`fc2`): hay 10 clases diferentes en el conjunto de datos Fashion-MNIST, por lo tanto, la capa de salida tiene 10 neuronas, una para cada clase.\n",
    "\n",
    "En `PyTorch`, el concepto de `device` permite que los cálculos se realicen en una CPU o GPU (si está disponible). Esto puede generar problemas dado que los tensores deben estar en el mismo dispositivo para poder operar con ellos. Por ejemplo, el conjunto de datos puede estar en la CPU, mientras que el modelo puede estar en la GPU. Para evitar este problema, se utiliza la función `to(DEVICE)` para mover los tensores a un dispositivo dado.\n",
    "\n",
    "***Nota***\n",
    "\n",
    "Una estrategia interesante en el caso de modelo(gpu) y datos(cpu) es agregar el argumento `pin_memory=True` al constructor de la clase `DataLoader`. Esto acelera la transmisión de datos entre dispositivos, dado que se fijan las páginas de memoria en la RAM destinadas al almacenamiento de los datos. Este acercamiento asegura una transmisión más rápida, pero utiliza más memoria RAM.\n",
    "\n",
    "Lamentablemente, la clase `DataLoader` no permite cargar todos los datos directamente en la GPU, por lo que se debe utilizar el argumento `pin_memory=True` y luego mover los batches de datos a la GPU con `to(DEVICE)`.\n",
    "\n",
    "Esto tiene sentido dado que la GPU tiene una memoria mucho más limitada que la RAM, en nuestro Fashion-MNIST cabe en una GPU moderna, pero obviamente no es el caso para datasets más grandes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_network import *\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "model = NeuralNetwork().to(DEVICE)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener el primer lote del DataLoader\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "# Tomar la primera imagen y etiqueta del lote\n",
    "single_image = images[0]\n",
    "single_label = labels[0]\n",
    "\n",
    "# Visualizar la imagen\n",
    "plt.imshow(single_image[0].numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Etiqueta: {LABELS[single_label.item()]}\")\n",
    "plt.show()\n",
    "\n",
    "single_image = single_image.to(DEVICE) \n",
    "# Pasar la imagen a través del modelo\n",
    "output = model(single_image)\n",
    "prediction = torch.argmax(output, dim=1)\n",
    "\n",
    "print(f\"Predicción del modelo: {LABELS[prediction.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la red neuronal durante 10 épocas con el conjunto `train`, y evaluamos el rendimiento del clasificador sobre el conjunto `eval`. \n",
    "\n",
    "Para el entrenamiento utilizamos la función de pérdida de entropía cruzada, ya que es una buena opción para problemas de clasificación multiclase. Y se usa el descenso por gradiente estocástico (SGD) como nuestro optimizador, con una tasa de aprendizaje de 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_and_test import train_model, test_model\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "train_accuracies = []\n",
    "eval_accuracies = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}:\")\n",
    "    \n",
    "    train_loss, train_acc = train_model(train_dataloader, model, loss_fn, optimizer, DEVICE)\n",
    "    eval_loss, eval_acc = test_model(eval_dataloader, model, loss_fn, DEVICE)\n",
    "    \n",
    "    print(f\"Train loss {train_loss}, Eval loss {eval_loss}, Train accuracy {train_acc}, Eval accuracy {eval_acc}\\n-------------------------------\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    eval_losses.append(eval_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    eval_accuracies.append(eval_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra la evolución de la pérdida en el conjunto de entrenamiento y de la accuracy sobre el conjunto de validación en función de las iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Entrenamiento', color='tab:red')\n",
    "plt.plot(eval_losses, label='Validación', color='tab:orange')\n",
    "plt.title('Evolución de la perdida')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perdida')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Entrenamiento', color='tab:red')\n",
    "plt.plot(eval_accuracies, label='Validación', color='tab:blue')\n",
    "plt.title('Evolución de Accuracy')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar una mejora en la precisión y una disminución en la pérdida a medida que avanzan las épocas. Esto indica que el modelo está aprendiendo a clasificar mejor las imágenes de Fashion-MNIST.\n",
    "\n",
    "El modelo alcanzó una precisión de aproximadamente un 77% sobre el conjunto de validación. Lo cual es un buen resultado para un modelo base, este desempeño establece un punto de referencia para comparar con los modelos de los siguientes puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir tres arquitecturas adicionales:\n",
    "\n",
    "**Arquitectura 1** \n",
    "\n",
    "`NeuralNetwork1` es una red neuronal con dos capas ocultas, la primera con 64 unidades y la segunda con 32 unidades. Ambas capas utilizan la función sigmoide como función de activación. \n",
    "\n",
    "* Propuesta: aumentar la complejidad del modelo para mejorar la precisión, agregando más unidades y capas ocultas, para que el modelo pueda aprender patrones más complejos.\n",
    "\n",
    "**Arquitectura 2**\n",
    "\n",
    "`NeuralNetwork2` es una red neuronal con una capa oculta de 64 unidades que utiliza la función sigmoide como función de activación.\n",
    "\n",
    "* Propuesta: Reducir la complejidad al tener una única capa oculta puede ayudar a evitar el sobreajuste y a mejorar la convergencia en conjuntos de datos más pequeños.\n",
    "  \n",
    "**Arquitectura 3**\n",
    "\n",
    "`NeuralNetwork3` es una red neuronal con una capa oculta de 32 unidades que utiliza la función ReLU como función de activación. \n",
    "\n",
    "* Propuesta: Ver los resultados al cambiar la función de activación de la capa oculta a ReLU, ya que es una función de activación más moderna y que suele dar buenos resultados.\n",
    "\n",
    "En cada caso, se evalúa el rendimiento del clasificador sobre el conjunto de validación, utilizando diferentes valores de tasa de aprendizaje. Los resultados de estas evaluaciones se utilizarán para seleccionar la mejor arquitectura y parámetros de entrenamiento para nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_network_3 import *\n",
    "from src.neural_network_1 import *\n",
    "from src.neural_network_2 import *\n",
    "\n",
    "model1 = NeuralNetwork1().to(DEVICE)\n",
    "model2 = NeuralNetwork2().to(DEVICE)\n",
    "model3 = NeuralNetwork3().to(DEVICE)\n",
    "\n",
    "print (model1)\n",
    "print (model2)\n",
    "print (model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.train_and_test import train_and_evaluate\n",
    "import pandas as pd\n",
    "TASA_APRENDIZAJE = [0.001, 0.01, 0.1, 0.5]\n",
    "epochs = 10\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def results_to_csv(model,model_name):\n",
    "    results_model = []\n",
    "    for lr in TASA_APRENDIZAJE:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)         \n",
    "        results = train_and_evaluate(epochs, loss_fn, optimizer, model, train_dataloader, eval_dataloader, lr,  DEVICE)\n",
    "        results_model.append(results)\n",
    "    results = pd.concat(results_model)\n",
    "    results.to_csv(f'data/{model_name}.csv', index=False)\n",
    "\n",
    "if not os.path.exists('data/model1.csv'): results_to_csv(model1, 'model1')\n",
    "if not os.path.exists('data/model2.csv'): results_to_csv(model2,'model2')\n",
    "if not os.path.exists('data/model3.csv'): results_to_csv(model3,'model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "TASA_APRENDIZAJE = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "def plot_accuracy(models):\n",
    "    fig, axs = plt.subplots(len(models), 1, figsize=(8, 3* len(models)))\n",
    "    colores = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "    for j, model in enumerate(models):\n",
    "        results_csv = 'data/' + model + '.csv'\n",
    "        results = pd.read_csv(results_csv)\n",
    "\n",
    "        for i, lr in enumerate(TASA_APRENDIZAJE):\n",
    "            subset = results[results['Tasa de aprendizaje'] == lr]\n",
    "            epochs = subset['Epoch']\n",
    "            eval_acc = subset['Eval Accuracy']\n",
    "            train_acc = subset['Train Accuracy']\n",
    "\n",
    "            axs[j].plot(epochs, eval_acc, label=f'{model} Eval lr={lr}', color=colores[i])\n",
    "            axs[j].plot(epochs, train_acc, label=f'{model} Train lr={lr}', linestyle='--', color=colores[i])\n",
    "\n",
    "        axs[j].set_ylabel('Precisión (%)')\n",
    "        axs[j].set_title(f'Evolución de la precisión - {model}')\n",
    "        axs[j].legend(loc='upper left', bbox_to_anchor=(1, 1), title='Tasas de Aprendizaje')\n",
    "\n",
    "    axs[-1].set_xlabel('Épocas')\n",
    "\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Llamada a la función con los modelos deseados\n",
    "plot_accuracy(['model1', 'model2', 'model3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos que mejor se desempeñaron fueron `NeuralNetwork1` y `NeuralNetwork2`, ambos con una precisión de aproximadamente un 80% sobre el conjunto de validación. En ambos casos, la tasa de aprendizaje que mejor funcionó fue 0.1. \n",
    "\n",
    "A continuación se muestra la evolución de la precisión sobre el conjunto de validación en función de las iteraciones para `NeuralNetwork1` y `NeuralNetwork2`. De esta forma podremos comparar el desempeño de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.train_and_test import plot_results\n",
    "\n",
    "model2_results = pd.read_csv('data/model2.csv')\n",
    "model2_subset = model2_results[model2_results['Tasa de aprendizaje'] == 0.1]\n",
    "\n",
    "model1_results = pd.read_csv('data/model1.csv')\n",
    "model1_subset = model1_results[model1_results['Tasa de aprendizaje'] == 0.1]\n",
    "\n",
    "\n",
    "plot_results([model2_subset, model1_subset], [ 'Modelo 2', 'Modelo 1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las partes siguientes tomaremos el modelo `NeuralNetwork2` con una tasa de aprendizaje de 0.1 como nuestro modelo final. \n",
    "\n",
    "#### Regularización\n",
    "**Regularización L2** Se basa en la idea de que los pesos grandes son más propensos a sobre ajustarse que los pesos pequeños. Por lo tanto, penaliza los pesos grandes y evita que los pesos crezcan demasiado durante el entrenamiento.\n",
    "\n",
    "**Dropout** Es una técnica de regularización que consiste en desactivar aleatoriamente un porcentaje de las neuronas de la red durante el entrenamiento. Esto evita que las neuronas se vuelven demasiado dependientes de las neuronas de la capa anterior y, por lo tanto, evitar el sobreajuste.\n",
    "\n",
    "Elegimos como mecanismo de **regularización L2** ya que es un método simple de implementar y efectivo para evitar el sobreajuste. La implementación en PyTorch se logra al agregar un valor a `weight_decay` al optimizador SGD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_and_test import plot_results\n",
    "\n",
    "TASA_APRENDIZAJE = 0.1\n",
    "TASA_L2 = 0.008\n",
    "epochs = 10\n",
    "\n",
    "model_final = NeuralNetwork2().to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_final.parameters(), lr=TASA_APRENDIZAJE, weight_decay=TASA_L2)\n",
    "\n",
    "if not os.path.exists('data/model_final.csv'):\n",
    "    results = train_and_evaluate(epochs, loss_fn, optimizer, model_final, train_dataloader, eval_dataloader, TASA_APRENDIZAJE,  DEVICE)\n",
    "    results.to_csv(f'data/model_final.csv', index=False)\n",
    "    torch.save(model_final.state_dict(), \"data/model_final.pth\")\n",
    "\n",
    "results_final = pd.read_csv('data/model_final.csv')\n",
    "\n",
    "results_1 = pd.read_csv('data/model2.csv')\n",
    "\n",
    "plot_results([results_final, results_1[results_1['Tasa de aprendizaje'] == 0.1]], ['Modelo Final', 'Modelo 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar la evolución de Accuracy sobre el conjunto de validación en función de las iteraciones para `NeuralNetwork2` con y sin regularización L2. \n",
    "\n",
    "En ambos casos 'Train Accuracy' aumenta progresivamente, mientras que 'Validation Accuracy' aumenta pero se estabiliza. En ambos modelos se observa que la precisión sobre el conjunto de entrenamiento es mayor que la precisión sobre el conjunto de evaluación. \n",
    "\n",
    "La pérdida es mayor en el modelo con regularización L2, esto se debe a que la regularización L2 penaliza los pesos grandes, lo que hace que la pérdida sea mayor.La diferencia entre la precisión sobre el conjunto de entrenamiento y el conjunto de validación es menor en el modelo con regularización L2, lo que indica que el modelo con regularización L2 generaliza mejor. Sin embargo, la precisión es menor en el modelo con regularización L2, lo que indica que el modelo con regularización L2 no es tan bueno como el modelo sin regularización L2.\n",
    "\n",
    "Dado estos resultados, decidimos implementar **Dropout** para ver si podemos mejorar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_and_test import plot_results\n",
    "from src.neural_network_reg import *\n",
    "TASA_APRENDIZAJE = 0.1\n",
    "epochs = 10\n",
    "\n",
    "model_final_2 = NeuralNetworkWithDropout(dropout_rate=0.4).to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_final.parameters(), lr=TASA_APRENDIZAJE)\n",
    "\n",
    "if not os.path.exists('data/model_final2.csv'):\n",
    "    results = train_and_evaluate(epochs, loss_fn, optimizer, model_final, train_dataloader, eval_dataloader, TASA_APRENDIZAJE,  DEVICE)\n",
    "    results.to_csv(f'data/model_final2.csv', index=False)\n",
    "    torch.save(model_final.state_dict(), \"data/model_final2.pth\")\n",
    "\n",
    "results_final = pd.read_csv('data/model_final2.csv')\n",
    "results_1 = pd.read_csv('data/model2.csv')\n",
    "\n",
    "plot_results([results_final, results_1[results_1['Tasa de aprendizaje'] == 0.1]], ['Modelo Final', 'Modelo 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando Dropout con una probabilidad de 0.4, se puede observar la evolución de accuracy sobre el conjunto de validación en función de las iteraciones para `NeuralNetwork2` con y sin Dropout. Lo cual son mejores resultados que al utilizar regularización L2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomaremos el modelo `NeuralNetwork2` con una tasa de aprendizaje de 0.1 y Dropout con una probabilidad de 0.4 como nuestro modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PLT_LABELS = [\"T-Shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\" ]\n",
    "model_final = NeuralNetwork2().to(DEVICE)\n",
    "model_final.load_state_dict(torch.load(\"data/model_final2.pth\"))\n",
    "\n",
    "model_final.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "img_with_entropy = []\n",
    "\n",
    "def entropy(probabilities):\n",
    "    # MinMaxScaler para que no haya valores negativos.\n",
    "    probabilities = (probabilities - probabilities.min()) / (probabilities.max() - probabilities.min())\n",
    "    # Filtro probabilidades nulas (log2(0) = -inf)\n",
    "    non_zero_probabilities = [p for p in probabilities if p != 0]\n",
    "    # Normalizar probabilidades.\n",
    "    normalized_probabilities = non_zero_probabilities / np.sum(non_zero_probabilities)\n",
    "\n",
    "    entropy = -np.sum([p * np.log2(p) for p in normalized_probabilities])\n",
    "    return entropy\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model_final(X)\n",
    "        #predicted, actual = LABELS[pred[0].argmax(0).item()], LABELS[y[0].item()]\n",
    "        predictions = torch.argmax(pred, dim=1)\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "        for X, y, pred, predictions in zip(X, y, pred, predictions):\n",
    "            img_with_entropy.append({\n",
    "                \"img\": X, \n",
    "                \"value\":y.cpu().numpy(), \n",
    "                \"prediction\":predictions.cpu().numpy(),\n",
    "                \"entropy\": entropy(pred.numpy())\n",
    "            })\n",
    "            \n",
    "        #print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "# Matriz de confusión\n",
    "confusion_mat = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(f'Exactitud: {accuracy:.4f}')\n",
    "print(f'Precisión: {precision:.4f}')\n",
    "print(f'Recuerdo: {recall:.4f}')\n",
    "print(f'Medida F1: {f1:.4f}')\n",
    "\n",
    "cmd_decision_tree = ConfusionMatrixDisplay(confusion_matrix=confusion_mat, display_labels=PLT_LABELS)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmd_decision_tree.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análisis de Matriz de confusión\n",
    "\n",
    "Se observa como los Tags de clasificación se pueden agrupar en grupos de prendas que a priori se puede decir son similares. Es decir, el modelo no suele confundir prendas que son claramente distintas, como un calzado y una remera.\n",
    "\n",
    "Las prendas se pueden agrupar en los siguientes grupos para los cuales los miembros de dichos grupos son más confundibles entre sí para el clasificador:\n",
    "\n",
    "* Shirt, T-Shirt, Pullover, Dress, Coat\n",
    "* Sneaker, Sandal, Ankle Boot\n",
    "* Bag\n",
    "* Trouser\n",
    "\n",
    "Se observa como el clasificador claramente suele clasificar erróneamente las prendas de la parte superior entre sí, y los calzados también. Esto, claramente, es esperable ya que las prendas al pertenecer a una misma parte del cuerpo tienden a ser similares. Es por esto también que se espera que las imágenes con mayor entropía pertenezcan a los primeros grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparación de resultados con los datos del sitio web de Fashion-MNIST\n",
    "\n",
    "Basandonos en los datos de la página [Fashion-MNIST](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#), nuestro modelo no se aleja del rango de Accuracy de los modelos de un rango entre 70% y 89%, por lo que podemos decir que nuestro modelo es aceptable. \n",
    "\n",
    "Las configuraciones con capas adicionales y activación \"relu\" demuestran mejoras en el accuracy, destacando la importancia de la complejidad del modelo en la captura de patrones más sofisticados. En nuestro caso, tal vez con mayor capas y/o activación \"relu\" podríamos haber obtenido un mejor resultado para la identificación de las prendas entre los grupos mencionados anteriormente.\n",
    "\n",
    "A su vez, los modelos más complejos clasificadores MLP requieren más tiempo de entrenamiento, por lo que es importante encontrar un equilibrio entre la complejidad del modelo y el tiempo de entrenamiento.Es consistente con lo que se observa en la práctica, donde los modelos más complejos tienden a tener un mejor rendimiento, pero también requieren más tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementos más difíciles de clasificar\n",
    "\n",
    "Para encontrar cuáles elementos son más difíciles de clasificar para la red se calcula la entropía de cada predicción. Esta medida es un valor que muestra la confianza que tiene un clasificador para identificar una prenda, penaliza el otorgar probabilidades altas a varias etiquetas. Por ejemplo, decir que la probabilidad es 0.25 para 4 etiquetas. \n",
    "\n",
    "A pesar que se usa la función de activación `Sigmoide`, la cual no puede retornar valores negativos, se necesita aplicar MinMaxScaler a los valores devueltos por el clasificador ya que los pesos de la red pueden hacer que algunos valores sean negativos. Al aplicar el MinMaxScaler todos los valores para cada etiqueta son mayor o igual a 0.\n",
    "```python\n",
    "# MinMaxScaler\n",
    "(X - X.min()) / (X.max() - X.min())\n",
    "```\n",
    "\n",
    "Luego normalizamos los valores devueltos para que correspondan a un valor de probabilidad (entre 0 y 1) y aplicamos la fórmula de entropía para calcular el valor de entropía que devuelve el clasificador para la instancia.\n",
    "\n",
    "```python\n",
    "entropy = -np.sum([p * np.log2(p) for p in normalized_probabilities])\n",
    "```\n",
    "\n",
    "Finalmente debido a que se tienen 10 etiquetas la máxima entropía posible es 3.322 ( log2(10) ) dada por equiprobabilidad entre todas las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_img = sorted(img_with_entropy, key=lambda x: x[\"entropy\"], reverse=True)\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 4\n",
    "# Show first 10\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample = sorted_img[i]\n",
    "    img, label, prediction, entropy_val = sample[\"img\"], sample[\"value\"], sample[\"prediction\"], sample[\"entropy\"]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'Pieza: {LABELS[int(label)]} \\nPrediccion: {LABELS[int(prediction)]} \\nEntropia: {entropy_val:4f}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "#\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se asumió previamente, la mayoría de imágenes que dificultan la clasificación para el clasificador son aquellas que pertenecen al subconjunto más grande de prendas con las que el clasificador suele predecir erróneamente, las prendas superiores. Es decir, las prendas con mayor entropía se corresponden con lo mostrado en la matriz de confusión, ya que al dudar cuál es la correcta clasificación el clasificador es más propenso a equivocarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía.\n",
    "\n",
    "- [Tutorial de PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "- [Fashion-MNIST1](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
