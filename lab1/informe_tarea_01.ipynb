{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1, Grupo 02 - Arboles de decisión\n",
    "\n",
    "- Santiago Alaniz, 5082647-6, santiago.alaniz@fing.edu.uy\n",
    "- Bruno De Simone, 4914555-0, bruno.de.simone@fing.edu.uy\n",
    "- María Usuca, 4891124-3, maria.usuca@fing.edu.uy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Implementar un modelo que explique la deserción de estudiantes en la universidad.\n",
    " \n",
    "Se pide:\n",
    "\n",
    "- **(a)** Implementar una variante del algoritmo `ID3` agregandole los siguientes *hiperparametros*:\n",
    "    - **i)** `min_samples_split`: cantidad mínima de ejemplos para generar un nuevo nodo; en caso de que no se llegue a la cantidad requerida, se debe formar una hoja.\n",
    "    - **ii)** `min_split_gain`: ganancia mínima requerida para partir por un atributo; si ningún atributo llega a ese valor, se debe formar una hoja.\n",
    "- **(b)** Utilizar el algoritmo implementado en **(a)** para construir un arbol de decision, evaluar resultados utilizando el dataset provisto.\n",
    "- **(c)** Discuta como afecta la variacion de los hiperparametros con los modelos obtenidos.\n",
    "- **(d)** Corra los algoritmos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer` y compare los resultados.\n",
    "\n",
    "El dataset que vamos a considerar (con su debido preprocesamiento) es *Predict students dropout and accademic success* con **36 atributos y mas de 4000 instancias.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño\n",
    "\n",
    "El apartado de diseño engloba todas las decisiones que tomamos a la hora de cumplir con las subtareas planteadas en la seccion anterior. \n",
    "\n",
    "Podemos identificar las siguientes etapas:\n",
    "\n",
    "- **Carga de datos y Particionamiento**: Inicialización de los datos de los archivos CSV en un DataFrame de Pandas.\n",
    "- **Pre-procesamiento de datos**: Transformaciones necesarias para que los datos puedan ser utilizados por el modelo.\n",
    "- **Algoritmo**: Comentarios sobre la implementacion del algoritmo asi como las decisiones tomadas para su implementacion.\n",
    "- **Evaluacion**: Prueba del modelo con diferentes hiperparametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos y particionamiento\n",
    "\n",
    "En este apartado vamos a inicializar los datos siguiendo un esquema clásico de aprendizaje automático:\n",
    "\n",
    "- **Carga de datos**: Cargamos los datos desde el fichero `csv` y los almacenamos en un `DataFrame` de `pandas`.\n",
    "- **Particionamiento**: Particionamos los datos en dos conjuntos con `train_test_split` de `sklearn`.\n",
    "    - `train` para entrenar el modelo.\n",
    "    - `test` para evaluar el modelo.\n",
    "    - `test` para evaluar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = './assets/data.csv'\n",
    "SEED_NUMBER = 342\n",
    "TEST_SIZE   = 0.4\n",
    "DEVEL_SIZE  = 0.5\n",
    "\n",
    "data = pd.read_csv(CSV_PATH, sep=';')\n",
    "\n",
    "train, test = train_test_split(data, test_size= TEST_SIZE, random_state= SEED_NUMBER)\n",
    "test, devel = train_test_split(test, test_size= DEVEL_SIZE, random_state= SEED_NUMBER)\n",
    "\n",
    "train_indices   = set(train.index)\n",
    "devel_indices   = set(devel.index)\n",
    "test_indices    = set(test.index)\n",
    "\n",
    "assert len(train_indices.intersection(devel_indices)) == 0\n",
    "assert len(train_indices.intersection(test_indices)) == 0\n",
    "assert len(devel_indices.intersection(test_indices)) == 0\n",
    "\n",
    "print(f'<train: {train.shape[0]}, devel: {devel.shape[0]}, test: {test.shape[0]} >')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefinición de los valores del atributo objetivo `Target`.\n",
    "\n",
    "El atributo objetivo `Target` es un atributo categórico que indica el desenlace del estudiante en su vida académica. Este atributo tiene 3 posibles valores: \n",
    "\n",
    "- `Enrolled` (inscripto)\n",
    "- `Dropout` (abandono)\n",
    "- `Graduate` (graduado).\n",
    "\n",
    "La idea es construir un modelo sobre la deserción de los estudiantes, por lo que se decide agrupar los valores `Enrolled` y `Graduate` en un solo valor. \n",
    "\n",
    "-  0 &rarr; `Dropout`\n",
    "-  1 &rarr; `Enrolled` o `Graduate`\n",
    "\n",
    "**Nota**: \n",
    "La siguiente redefinición de atributos genera un desbalance en el atributo `Target`. De todas formas, continuaremos con el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, devel, test]:\n",
    "    df['Target'] = df['Target'].apply(lambda x: 0 if x == 'Dropout' else 1)\n",
    "\n",
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de atributos continuos.\n",
    "\n",
    "La [discretización](https://en.wikipedia.org/wiki/Data_binning) provee un mecanismo para particionar valores continuos en un número finito de valores discretos.\n",
    "\n",
    "De los [36 atributos presentes](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success) en el dataset, estos son listados como continuos:\n",
    "\n",
    "- `Previous qualification (grade)`\n",
    "- `Admission grade`\n",
    "- `Unemployment rate`\n",
    "- `Inflation rate`\n",
    "- `GDP`\n",
    "\n",
    "Para discretizar estos atributos, utilizaremos el módulo `scikit-learn.preprocessing`. \n",
    "\n",
    "En particular, la clase [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) con los siguientes parámetros:\n",
    "\n",
    "- `encode= 'ordinal'` (codificación de los bins) devuelve un array de enteros indicando a que bin pertenece cada valor.\n",
    "- `strategy='kmeans'` (estrategia de discretización) utiliza el algoritmo de [k-means](https://en.wikipedia.org/wiki/K-means_clustering) para determinar los bins. \n",
    "\n",
    "Finalmente, identificar estos atributos en el dataset es una tarea sencilla, ya que son los únicos del tipo `float64`.\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Hay un error en la [documentación de los datos](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success), figuran como discretos dos campos representados con `float64`:\n",
    "\n",
    "- `Curricular units 1st sem (grade)`\n",
    "- `Curricular units 2nd sem (grade)` \n",
    "\n",
    "Decidimos discretizarlos de todas formas, ya que algunas de las entradas tienen valores no enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "float64_cols = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for float64_col in float64_cols:\n",
    "    float64_discretizer = KBinsDiscretizer(subsample=None, encode='ordinal', strategy='kmeans')\n",
    "    train[[float64_col]]    = float64_discretizer.fit_transform(train[[float64_col]]).astype(int)\n",
    "    devel[[float64_col]]    = float64_discretizer.transform(devel[[float64_col]]).astype(int)\n",
    "    test[[float64_col]]     = float64_discretizer.transform(test[[float64_col]]).astype(int)\n",
    "\n",
    "train[float64_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario sobre el resto de los valores (discretos)\n",
    "\n",
    "Los valores discretos son ideales para `ID3` porque el algoritmo puede manejarlos directamente sin necesidad de transformaciones adicionales. Sin embargo, es crucial tener en cuenta el número de valores únicos que un atributo discreto puede tener.\n",
    "\n",
    "Somos conscientes que no existe un \"buen número\" de valores discretos distintos para un atributo en un árbol de decisión como el ID3.\n",
    "Depende de varios factores, incluidos el tamaño del conjunto de datos, la complejidad del problema y el riesgo de sobreajuste. \n",
    "\n",
    "Además otro factor a tomar en cuenta es que los valores discretos pueden categorizar elementos complejos donde su valor numérico no tenga correlación con su valor semántico. Por ejemplo, la columna `Nationality` representa con un entero distintos países, si quisiéramos categorizar ese valor de forma significativa tendríamos que construir super categorías para los países (por ejemplo 0-Europa, 1-America, etc).\n",
    "\n",
    "Otra alternativa es aplicar [one-hot encoding](https://datagy.io/sklearn-one-hot-encode/) a los valores discretos, pero esto aumentaría la dimensionalidad del dataset y podría generar problemas de performance.\n",
    "\n",
    "La conclusión final es que el procesamiento de valores discretos es una tarea que excede el objetivo de este laboratorio, por eso decidimos no aplicar ningún preprocesamiento a los valores discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "int64_cols      = data.select_dtypes(include=['int64']).columns\n",
    "unique_values   = data[int64_cols].nunique()\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = unique_values.plot(kind='bar')\n",
    "plt.title('Valores Discretos')\n",
    "plt.xlabel('Atributos')\n",
    "plt.ylabel('Valores Distintos')\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "El algoritmo a desarrollar es `ID3` como se presentó en el teórico, con la incorporación de ciertos meta-parámetros que buscan evitar el sobreajuste del modelo.\n",
    "\n",
    "Para lograr este objetivo, se tuvo en consideración las siguientes subtareas:\n",
    "\n",
    "1. Sobre las variables/estructuras necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "2. `ID3_utils.py`: Un módulo con estructuras/funciones auxiliares para la implementación de `ID3`.\n",
    "3. `src.G02DecisionTrees.ID3Classifier`: Nuestro algoritmo inspirado en los clasificadores de `sklearn`.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre las variables necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "Para implementar `ID3` necesitamos definir las siguientes variables:\n",
    "\n",
    "Entradas:\n",
    "\n",
    "- `Examples`: conjunto de ejemplos de entrenamiento (`train`).\n",
    "- `Target_attribute`: atributo objetivo (`Target`).\n",
    "- `Attributes`: conjunto de atributos (el resto de las columnas).\n",
    "\n",
    "Estructura de Datos y Funciones Auxiliares:\n",
    "\n",
    "- `node`: estructura de datos que representa un nodo del árbol.\n",
    "- `max_gain_attr`: función que devuelve el atributo con mayor ganancia de información.\n",
    "- `attributes_values`: diccionario que mapea atributos con todos sus valores posibles.\n",
    "\n",
    "\n",
    "Para obtener `attributes_values` recorremos todos los atributos y obtenemos sus valores únicos. Hay que tener en cuenta que los atributos continuos fueron discretizados, por lo que sus valores son enteros que se encuentran en un rango acotado. (Preprocesamiento de atributos continuos).\n",
    "\n",
    "El resto de las Estructuras de Datos y Funciones Auxiliares se encuentran en el módulo `ID3_utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "int64_cols      = data.select_dtypes(include=['int64']).columns\n",
    "attrs_values    = {attr: sorted(data[attr].unique()) for attr in int64_cols}\n",
    "float64_cols    = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "attrs_values.update({col: list(range(5)) for col in float64_cols})\n",
    "\n",
    "print(f'attrs: {len(attrs_values.keys())}, Algunos valores de atributos discretos: \\n')\n",
    "for k in list(attrs_values.keys())[:5]: print(f\"{k}: {attrs_values[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ID3_utils.py`: Un módulo con estructuras/funciones auxiliares para la implementación de `ID3`.\n",
    "\n",
    "Este módulo de Python está diseñado para implementar árboles de decisión utilizando el algoritmo ID3. A continuación se describen los componentes principales:\n",
    "\n",
    "- `ID3Node`: Esta es una clase que representa un nodo en el árbol de decisión. Cada nodo tiene una etiqueta (`label`) que indica el atributo que se está evaluando en ese nodo, y una ganancia de información (`info_gain`) que indica cuánta incertidumbre se reduce al dividir el conjunto de datos según ese atributo.\n",
    "- `node`: Esta es una función auxiliar que facilita la creación de nuevos nodos. Acepta una etiqueta y una ganancia de información como argumentos y devuelve una instancia de `ID3Node`.\n",
    "- `entropy`: Esta función calcula la entropía de un conjunto de datos dado un atributo objetivo (`attr_tget`). La entropía es una medida de la incertidumbre o el desorden en los datos.\n",
    "- `max_gain_attr`: Esta función determina qué atributo tiene la máxima ganancia de información cuando se utiliza para evaluar el mejor nodo candidato.\n",
    "- `evaluate`: Esta función evalúa un conjunto de datos y busca en el árbol de decisión para determinar la clase de cada ejemplo. Devuelve una lista de predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ID3_utils import max_gain_attr, node\n",
    "\n",
    "attr, gain  = max_gain_attr(train, 'Target', attrs_values)\n",
    "id3_node    = node(attr, info_gain= gain)\n",
    "\n",
    "id3_node.children[attrs_values[attr][0]] = node('Nationality', 0.02)\n",
    "\n",
    "print(f\"node: {id3_node.label, id3_node.info_gain, id3_node.children}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `src.G02DecisionTrees.ID3Classifier`: Nuestro clase-clasificadora inspirada en `sklearn`.\n",
    "\n",
    "Nuestro algoritmo está encapsulado en una clase clasificadora que está diseñada/inspirada en base a los clasificadores de `scikit-learn`.\n",
    "La principal motivación para hacerlo de esta forma es el objetivo de comparar los resultados de nuestro algoritmo con los de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "\n",
    "Entonces, consideramos acertado modelar esta clase como si se tratara de una clase más de `scikit-learn.`\n",
    "\n",
    "**Clase ID3Classifier**: Define el clasificador ID3.\n",
    "\n",
    "- `__init__`: Inicializa el clasificador con los meta-parámetros. \n",
    "  - `min_samples_split` y `min_split_gain`: requeridas por la letra del obligatorio, limitan el crecimiento del árbol. \n",
    "  - `attr_values`, `attrs` necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "`ID3Classifier` implementa funciones típicas de `scikit-learn`:\n",
    "\n",
    "- El método `fit` toma un DataFrame `X`, una serie `y` como entrada y construye un árbol de decisión con `_id3`.\n",
    "- El método `predict` utiliza el árbol para hacer predicciones en un nuevo conjunto de datos.\n",
    "- El método `score` evalúa la precisión del modelo utilizando `scikit-learn.accuracy_score`.\n",
    "    \n",
    "**`__id3`** implementa el algoritmo recursivamente para construir el árbol de decisión.\n",
    "\n",
    "```python\n",
    "## Mitchell, p. 68\n",
    "def __id3(self, exs, attr_tget, attrs):\n",
    "    same_value_attr_tget = exs[attr_tget].nunique() == 1\n",
    "    attrs_empty = len(attrs) == 0\n",
    "    \n",
    "    if same_value_attr_tget or attrs_empty: return utils.node(exs[attr_tget].mode()[0])\n",
    "\n",
    "    _attrs_values = { k: self.attrs_values[k] for k in attrs }\n",
    "    best_attr, gain = utils.max_gain_attr(exs, attr_tget, _attrs_values)\n",
    "    \n",
    "    if gain <= self.min_split_gain: return utils.node(exs[attr_tget].mode()[0])\n",
    "    \n",
    "    node = utils.node(best_attr, gain)\n",
    "    best_attr_values = self.attrs_values[best_attr]\n",
    "    \n",
    "    for attr_val in best_attr_values:\n",
    "        exs_i = exs[exs[best_attr] == attr_val]\n",
    "\n",
    "        if exs_i.shape[0] <= self.min_samples_split: \n",
    "          node.children[attr_val] = utils.node(exs[attr_tget].mode()[0])\n",
    "        else:\n",
    "          attrs_i = [attr for attr in attrs if attr != best_attr]\n",
    "          node.children[attr_val] = self.__id3(exs_i, attr_tget, attrs_i)\n",
    "    \n",
    "    return node\n",
    "```\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Vamos a modificar la columna `Target`  de `train` para forzar la creación de un ***`dummy classifier`***. En particular uno que siempre prediga `1` (inscripto o graduado). Obtendremos un árbol de decisión con un solo nodo hoja valor 1, como esta clase está desbalanceada favorablemente, tendremos un accuracy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.G02_decision_trees import ID3Classifier\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']), devel['Target']\n",
    "\n",
    "G02_dumb_clf = ID3Classifier(attrs_values= attrs_values)\n",
    "G02_dumb_clf.fit(train_X, train_y.apply(lambda x: 1))\n",
    "\n",
    "print(f'{G02_dumb_clf.tree} [\\\n",
    " label: {G02_dumb_clf.tree.label},\\\n",
    " info_gain: {G02_dumb_clf.tree.info_gain},\\\n",
    " children: {G02_dumb_clf.tree.children} ]'\n",
    ")\n",
    "\n",
    "G02_dumb_clf.score(devel_X, devel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación\n",
    "\n",
    "Como se nos ha comentado en el teórico, la evaluación de un modelo es una tarea compleja que requiere de un análisis profundo de los resultados obtenidos.\n",
    "En particular, la selección de métricas acorde al problema a resolver es una tarea que requiere de un conocimiento profundo del dominio.\n",
    "\n",
    "Sabemos que el dataset que estamos analizando tiene un desbalance en el atributo objetivo `Target`, por lo que la métrica de `accuracy` no es la más adecuada para evaluar el modelo. Por ejemplo un modelo que siempre predice un resultado con el valor de una clase favorable, tendrá un accuracy elevado (`G02_dumb_clf`) \n",
    "\n",
    "Vamos a utilizar la métrica [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) para evaluar el modelo, es adecuada para problemas con clases desbalanceadas.\n",
    "\n",
    "Como ya comentamos anteriormente, nuestro equipo convenientemente separó los datos en tres conjuntos:\n",
    "\n",
    "- `train`: para entrenar el modelo.\n",
    "- `devel`: para ajustar los hiperparametros y evaluaciones intermedias.\n",
    "- `test`: para evaluar el modelo final.\n",
    "\n",
    "Se utilizó una proporción 60/20/20 para los conjuntos `train`, `devel` y `test` respectivamente. Estos conjuntos además se encuentran mezclados de forma aleatoria y estratificados, de forma tal que la proporción de clases sea la misma en los tres conjuntos.\n",
    "\n",
    "***Nota***:\n",
    "\n",
    "Imprimimos esta proporción para dejar constancia. De la documentación de `sklearn.model_selection.train_test_split` se desprende que la estratificación es un comportamiento predeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_proportion = train_y.value_counts(normalize=True)\n",
    "devel_target_proportion = devel_y.value_counts(normalize=True)\n",
    "\n",
    "print(f'Train: {train_target_proportion}\\n')\n",
    "print(f'Devel: {devel_target_proportion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación\n",
    "\n",
    "En este apartado vamos a realizar una serie de experimentos.\n",
    "\n",
    "- Búsqueda con Grid Search para encontrar los mejores meta-parámetros de nuestro modelo.\n",
    "- Definición de nuestro modelo final.\n",
    "- Exploración de los modelos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "- Comparativa final de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search para encontrar los mejores hiperparametros de nuestro modelo.\n",
    "\n",
    "Para encontrar la mejor combinación de meta-parámetros para nuestro clasificador vamos a utilizar Grid Search. \n",
    "\n",
    "Primero vamos a definir un espacio de búsqueda tomando ciertas precauciones. La idea de los meta-parámetros es evitar el sobreajuste del modelo, sin estos elementos, un árbol de decisión puede crecer hasta tener un nodo por cada ejemplo de entrenamiento. \n",
    "\n",
    "Por ende, un árbol con muchos nodos es un árbol que está sobre ajustado. De forma análoga, tampoco queremos un árbol que solo tenga un nodo, como el `G02_dumb_clf` que siempre predice `1`.\n",
    "\n",
    "Sabemos que:\n",
    "\n",
    "- `min_samples_split` &rarr; cantidad mínima de ejemplos para generar un nuevo nodo.\n",
    "- `min_split_gain` &rarr; ganancia mínima requerida para partir por un atributo.\n",
    "\n",
    "No satisfacer estas condiciones fuerza la creación de un nodo hoja con el valor más común del atributo objetivo `Target`.\n",
    "\n",
    "Definimos el espacio de búsqueda inicial de la siguiente forma:\n",
    "\n",
    "- `min_samples_split` &rarr; (0, 885)\n",
    "- `min_split_gain` &rarr; (0.0, 0.5):\n",
    "\n",
    "Se busca en valores amplios inicialmente intentando no caer en un óptimo local y se ajustan los rangos de búsqueda en siguientes iteraciones. Luego de varias iteraciones se define la búsqueda final y para la cual se genera un mapa de calor se busca un rango que muestra la tendencia de cómo cambia el accuracy y más importante aún para nosotros el F1-Score.\n",
    "\n",
    "Los rangos finales son definidos como:\n",
    "\n",
    "- `min_samples_split` &rarr; (0, 150)\n",
    "- `min_split_gain` &rarr; (0.0, 0.3):\n",
    "\n",
    "En cada iteración de `ID3` el conjunto de entrenamiento se reduce en factor de cuantos ejemplos había para el valor del atributo pivotal. Por ejemplo, si el atributo pivotal es `Nationality` y el valor es `Uruguay`, entonces el conjunto de entrenamiento se reduce a los ejemplos que tienen `Nationality == Uruguay`. \n",
    "\n",
    "En resumen, el conjunto de ejemplos se reduce en factor del valor del atributo pivotal. `devel` tiene 885 ejemplos, es decir un 20% de los ejemplos de `train`. Nuestro método de grid search va a iterar entre el 0% y el 20% de la cantidad total de ejemplos de `train`.\n",
    "\n",
    "El límite superior surge de la ganancia máxima de un atributo en todo `train`. El límite inferior es 0.0 porque es el valor predeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from src.ID3_utils import max_gain_attr\n",
    "from src.G02_decision_trees import ID3Classifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "# Settie estos valores basado en heatmaps\n",
    "GRID_SAMPLES = 10\n",
    "MAX_MIN_SAMPLES_SPLIT = 150\n",
    "MAX_MIN_SPLIT_GAIN = 0.3\n",
    "\n",
    "attr, max_gain = max_gain_attr(train, 'Target', attrs_values)\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']), devel['Target']\n",
    "\n",
    "meta_params_grid = {\n",
    "    'min_samples_split': np.linspace(MAX_MIN_SAMPLES_SPLIT, 2, GRID_SAMPLES).astype(int),\n",
    "    'min_split_gain': np.linspace(MAX_MIN_SPLIT_GAIN, 0.0, GRID_SAMPLES)\n",
    "}\n",
    "\n",
    "def train_and_evaluate(mss_i, msg_j, train_X, train_y, devel_X, devel_y, attrs_values):\n",
    "    clf = ID3Classifier(attrs_values=attrs_values, min_samples_split=mss_i, min_split_gain=msg_j)\n",
    "    clf.fit(train_X, train_y)\n",
    "    clf_predicitions = clf.predict(devel_X)\n",
    "    f1 = f1_score(devel_y, clf_predicitions)\n",
    "    acc = accuracy_score(devel_y, clf_predicitions)\n",
    "    return f1, acc, mss_i, msg_j\n",
    "\n",
    "def grid_search_to_csv():\n",
    "    results = pd.DataFrame(columns=['f1_score', 'min_samples_split', 'min_split_gain'])\n",
    "    results_acc = pd.DataFrame(columns=['accuracy', 'min_samples_split', 'min_split_gain'])\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for mss_i in meta_params_grid['min_samples_split']:\n",
    "            for msg_j in meta_params_grid['min_split_gain']:\n",
    "                future = executor.submit(train_and_evaluate, mss_i, msg_j, train_X, train_y, devel_X, devel_y, attrs_values)\n",
    "                futures.append(future)\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            f1, acc, mss_i, msg_j = future.result()\n",
    "            results.loc[len(results)] = [f1, mss_i, msg_j]\n",
    "            results_acc.loc[len(results_acc)] = [acc, mss_i, msg_j]\n",
    "\n",
    "    results.to_csv('assets/grid_search.csv', index=False)\n",
    "    results_acc.to_csv('assets/grid_search_acc.csv', index=False)\n",
    "\n",
    "if not os.path.exists('assets/grid_search.csv'): grid_search_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de nuestro modelo final.\n",
    "\n",
    "Después de evaluar 100 modelos con grid search, construimos un `CSV` con los resultados obtenidos.\n",
    "\n",
    "- `grid_search.csv`: Resultados de la búsqueda con grid search.\n",
    "\n",
    "Vamos a utilizar `pandas` para obtener el promedio de los meta-parámetros que obtuvieron el mejor `f1_score`.\n",
    "\n",
    "Obteniendo así los meta-parametros para nuestro modelo final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grid_search = pd.read_csv('assets/grid_search.csv')\n",
    "\n",
    "max_f1_score = grid_search['f1_score'].max()\n",
    "best_params = grid_search[grid_search['f1_score'] == max_f1_score].iloc[0]\n",
    "\n",
    "max_min_samples_split = best_params['min_samples_split'].mean().astype(int)\n",
    "max_min_split_gain = best_params['min_split_gain'].mean()\n",
    "\n",
    "print(f'max_min_samples_split: {max_min_samples_split}')\n",
    "print(f'max_min_split_gain: {max_min_split_gain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos también un mapa de calor para mostrar la tendencia del F1-Score con la variación de los meta-parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV data into a pandas DataFrame\n",
    "f1_grid_data = pd.read_csv('assets/grid_search.csv')\n",
    "acc_grid_data = pd.read_csv('assets/grid_search_acc.csv')\n",
    "\n",
    "# Get unique values of min_samples_split and min_split_gain\n",
    "min_samples_split_values = sorted(f1_grid_data['min_samples_split'].unique())\n",
    "min_split_gain_values = sorted(f1_grid_data['min_split_gain'].unique())\n",
    "\n",
    "# Create a matrix of f1_score values\n",
    "f1_score_matrix = np.zeros((len(min_split_gain_values), len(min_samples_split_values)))\n",
    "acc_score_matrix = np.zeros((len(min_split_gain_values), len(min_samples_split_values)))\n",
    "for i, msg in enumerate(min_split_gain_values):\n",
    "    for j, mss in enumerate(min_samples_split_values):\n",
    "        f1_score_matrix[i, j] = f1_grid_data[(f1_grid_data['min_split_gain'] == msg) & (f1_grid_data['min_samples_split'] == mss)]['f1_score'].values[0]\n",
    "        acc_score_matrix[i, j] = acc_grid_data[(acc_grid_data['min_split_gain'] == msg) & (acc_grid_data['min_samples_split'] == mss)]['accuracy'].values[0]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# F1 Score Heatmap\n",
    "heatmap = axes[0].pcolor(f1_score_matrix, cmap='YlOrRd')\n",
    "fig.colorbar(heatmap, ax=axes[0])\n",
    "axes[0].set_title('F1 Score Heatmap')\n",
    "axes[0].set_xlabel('min_samples_split')\n",
    "axes[0].set_ylabel('min_split_gain')\n",
    "axes[0].set_xticks(np.arange(len(min_samples_split_values)) + 0.5, min_samples_split_values, rotation='vertical')\n",
    "axes[0].set_yticks(np.arange(len(min_split_gain_values)) + 0.5, min_split_gain_values)\n",
    "\n",
    "# Accuracy Heatmap\n",
    "heatmap = axes[1].pcolor(acc_score_matrix, cmap='YlOrRd')\n",
    "fig.colorbar(heatmap, ax=axes[1])\n",
    "axes[1].set_title('Accuracy Heatmap')\n",
    "axes[1].set_xlabel('min_samples_split')\n",
    "axes[1].set_ylabel('min_split_gain')\n",
    "axes[1].set_xticks(np.arange(len(min_samples_split_values)) + 0.5, min_samples_split_values, rotation='vertical')\n",
    "axes[1].set_yticks(np.arange(len(min_split_gain_values)) + 0.5, min_split_gain_values)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de los clasificadores `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "\n",
    "Vamos a indagar en los siguientes clasificadores `scikit-learn DecisionTreeClassifier, RandomForestClassifer`. Sobre todo manipular sus meta-parámetros para que, en la medida de lo posible, nuestro mejor clasificador compita con ellos en igualdad de condiciones.\n",
    "\n",
    "Por igualdad de condiciones nos referimos a las siguientes consideraciones:\n",
    "\n",
    "- **Meta-parametros**: Utilizar los mismos meta-parámetros que nuestro mejor clasificador. De no encontrar/detectar un meta-parámetro equivalente, utilizar el valor por defecto.\n",
    "- **Entreanamiento**: Utilizar el mismo conjunto de entrenamiento que nuestro mejor clasificador.\n",
    "- **Evaluacion**: Utilizar la misma métrica de evaluación que nuestro mejor clasificador.\n",
    "\n",
    "Tomamos estas consideraciones porque asumimos que los clasificadores de `scikit-learn` son robustos y estan optimizados para obtener los mejores resultados posibles.\n",
    "\n",
    "#### `scikit-learn DecisionTreeClassifier`\n",
    "\n",
    "Identificamos los siguientes meta-parámetros:\n",
    "\n",
    "- `criterion`: La función para medir la calidad de una partición. Utilizamos `entropy` porque es la misma que utiliza nuestro clasificador.\n",
    "- `min_samples_split`: Su definición es la misma que la de nuestro clasificador. Utilizamos el valor de nuestro mejor clasificador que casualmente es el valor por defecto.\n",
    "\n",
    "No existe un meta-parámetro equivalente a `min_split_gain`.\n",
    "\n",
    "#### `scikit-learn RandomForestClassifer`\n",
    "\n",
    "De forma similar al clasificador anterior, identificamos los siguientes meta-parámetros:\n",
    "\n",
    "- `criterion`: análogo al clasificador anterior, utilizamos `entropy`.\n",
    "- `min_samples_split`: análogo al clasificador anterior, utilizamos el valor por defecto.\n",
    "\n",
    "No existe un meta-parámetro equivalente a `min_split_gain`.\n",
    "\n",
    "En resumen, los clasificadores que consideramos más cercanos a nuestro mejor clasificador son:\n",
    "\n",
    "- `DecisionTreeClassifier` con `criterion='entropy'` y `min_samples_split=18`.\n",
    "- `RandomForestClassifer` con `criterion='entropy'` y `min_samples_split=18`.\n",
    "\n",
    "***Nota***:\n",
    "\n",
    "Hay un parámetro llamado `min_impurity_decrease` que es similar a `min_split_gain`, es una fórmula que aplica técnicas de look-ahead para determinar si un nodo debe ser dividido. Dado que nuestro clasificador es puramente greedy, no tiene sentido utilizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']) , devel['Target']\n",
    "\n",
    "fair_dt_clf = DecisionTreeClassifier(criterion= 'entropy', min_samples_split=18)\n",
    "fair_dt_clf.fit(train_X, train_y)\n",
    "\n",
    "fair_rf_clf = RandomForestClassifier(criterion= 'entropy', min_samples_split=18)\n",
    "fair_rf_clf.fit(train_X, train_y)\n",
    "\n",
    "print(f'DecisionTreeClassifier f1_score(devel): {f1_score(devel_y, fair_dt_clf.predict(devel_X))}')\n",
    "print(f'RandomForestClassifier f1_score(devel): {f1_score(devel_y, fair_rf_clf.predict(devel_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa final de los modelos.\n",
    "\n",
    "En este apartado vamos a comparar el desempeño de los modelos que hemos construido. Recordemos brevemente cuales son:\n",
    "\n",
    "- `G02_dumb_clf`: Un clasificador que siempre predice `1` (inscripto o graduado).\n",
    "- `G02_best_clf`: Nuestro mejor clasificador con los meta-parametros que obtuvieron el mejor `f1_score`.\n",
    "- `fair_dt_clf`: `DecisionTreeClassifier` con `criterion='entropy'`.\n",
    "- `fair_rf_clf`: `RandomForestClassifer` con `criterion='entropy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.G02_decision_trees import ID3Classifier\n",
    "\n",
    "G02_best_clf = ID3Classifier(attrs_values=attrs_values, min_samples_split=max_min_samples_split,\n",
    "                             min_split_gain=max_min_split_gain)\n",
    "\n",
    "G02_best_clf.fit(train_X, train_y)\n",
    "\n",
    "test_X, test_y = test.drop(columns=['Target']), test['Target']\n",
    "\n",
    "fair_dt_pred = fair_dt_clf.predict(test_X)\n",
    "fair_rf_pred = fair_rf_clf.predict(test_X)\n",
    "G02_best_pred = G02_best_clf.predict(test_X)\n",
    "G02_dumb_pred = G02_dumb_clf.predict(test_X)\n",
    "\n",
    "print(f'DecisionTreeClassifier  f1_score(test): {f1_score(test_y, fair_dt_pred)}')\n",
    "print(f'RandomForestClassifier  f1_score(test): {f1_score(test_y, fair_rf_pred)}')\n",
    "print(f'Best ID3Classifier      f1_score(test): {f1_score(test_y, G02_best_pred)}')\n",
    "print(f'Dumb ID3Classifier      f1_score(test): {f1_score(test_y, G02_dumb_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular matrices de confusión\n",
    "cm_decision_tree = confusion_matrix(test_y, fair_dt_pred)\n",
    "cm_random_forest = confusion_matrix(test_y, fair_rf_pred)\n",
    "cm_G02_best_clf = confusion_matrix(test_y, G02_best_pred)\n",
    "cm_G02_dumb_clf = confusion_matrix(test_y, G02_dumb_pred)\n",
    "\n",
    "# 0 = Dropout, 1 = Graduate or Enrolled\n",
    "labels = ['Dropout', 'Graduate\\nEnrolled']\n",
    "\n",
    "## Crear objetos ConfusionMatrixDisplay\n",
    "cmd_decision_tree = ConfusionMatrixDisplay(confusion_matrix=cm_decision_tree, display_labels=labels)\n",
    "cmd_random_forest = ConfusionMatrixDisplay(confusion_matrix=cm_random_forest, display_labels=labels)\n",
    "cmd_G02_best_clf = ConfusionMatrixDisplay(confusion_matrix=cm_G02_best_clf, display_labels=labels)\n",
    "cmd_G02_dumb_clf = ConfusionMatrixDisplay(confusion_matrix=cm_G02_dumb_clf, display_labels=labels)\n",
    "\n",
    "# Mostrar las matrices de confusión\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "cmd_decision_tree.plot(cmap=plt.cm.Blues, ax=axes[0][0])\n",
    "axes[0][0].set_title(\"Matriz de Confusión - Decision Tree\")\n",
    "\n",
    "cmd_random_forest.plot(cmap=plt.cm.Blues, ax=axes[0][1])\n",
    "axes[0][1].set_title(\"Matriz de Confusión - Random Forest\")\n",
    "\n",
    "cmd_G02_best_clf.plot(cmap=plt.cm.Blues, ax=axes[1][0])\n",
    "axes[1][0].set_title(\"Matriz de Confusión - G02 ID3Classifier\")\n",
    "\n",
    "cmd_G02_dumb_clf.plot(cmap=plt.cm.Blues, ax=axes[1][1])\n",
    "axes[1][1].set_title(\"Matriz de Confusión - Dumb Classifier\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "A lo largo de este laboratorio profundizamos en los árboles de decisión. En particular el algoritmo `ID3`, sus meta-parámetros y su implementación en python tomando como referencia los manuales teóricos de la materia. \n",
    "\n",
    "Tuvimos también un primer acercamiento a la metodología de experimentación en aprendizaje automático. Tratando de aplicar para cada etapa del proceso, algunas de las buenas prácticas que se han visto en clase.\n",
    "\n",
    "### Sobre los resultados obtenidos.\n",
    "\n",
    "Sin sorpresas para nosotros, `RandomForestClassifier` es el clasificador con mejor `f1_score`. Creemos que su característica de ensamble de diferentes árboles de decisión, más la diversidad de los mismos, reduce el sobreajuste y lo hace más robusto.\n",
    "\n",
    "Lo que sí es una sorpresa es que nuestro clasificador `G02_best_clf` obtuvo un `f1_score` similar al de `RandomForestClassifier`. Y no solo eso, sino que también obtuvo un `f1_score` mayor al de `DecisionTreeClassifier`. Creemos que esto se debe a los siguientes factores:\n",
    "\n",
    "**El criterio de \"igualdad de condiciones\" terminó favoreciendo a `G02_best_clf`:** Configurar los clasificadores de `scikit-learn` para que se ajusten a la dinámica de nuestra implementación `ID3` tuvo un efecto positivo en comparación con los de `scikit-learn`. Sobre todo considerando que `scikit-learn` es una librería robusta y optimizada.\n",
    "\n",
    "**La naturaleza greedy de `ID3` sumandole el desbalance de clases**: nuestra implementación de ID3 es un algoritmo \"greedy\" que hace divisiones locales óptimas, estas decisiones locales no necesariamente conducen a una solución global óptima. Pero sin embargo, hay un criterio de parada posible en cada iteración que puede explicar el fenómeno. \n",
    "\n",
    "- Al momento de crear un nodo hoja, asignarle el valor más común del atributo. Esto sesga a nuestro modelo a que (en una alta proporción) cuando tenga que definir un nodo hoja, lo haga con el valor más común del atributo objetivo `Target`.\n",
    "\n",
    "### Sobre el proceso de experimentación.\n",
    "\n",
    "Sobre los meta-parámetros, nos sorprendió que `min_samples_split` no tuviera un efecto significativo en el `f1_score`. De hecho el resultado apunta que el mejor valor es el por defecto.\n",
    "Sobre los meta-parámetros, notamos que el meta-parámetro más importante es `min_samples_split`, y que resultó beneficioso acotar el rango del grid search iterativamente ya que inicialmente el mejor resultado se daba con el valor por defecto (2) y luego se observó una mejora con el valor 18.\n",
    "\n",
    "`min_split_gain` en cambio hace que el F1-Score prácticamente no varíe en un rango \"amplio\".\n",
    "\n",
    "### Posibles mejoras.\n",
    "\n",
    "Somos conscientes que este laboratorio es el primero y que hay mucho por mejorar. A continuación listamos algunas de las mejoras que consideramos más importantes:\n",
    "\n",
    "- Preprocesamiento:\n",
    "\n",
    "    - **Supra-categorizar atributos discretos con muchos valores distintos**: Notamos que hay algunos atributos que pueden llegar a tener muchos valores distintos, por ejemplo `Nationality`. Creemos que es posible re-categorizar estos atributos, por ejemplo `Continente/Región` para que así el árbol de decisión no tenga tantos nodos y pueda generalizar mejor.\n",
    "    \n",
    "    - Aplicar one-hot encoding a los atributos discretos categóricos: Creemos que es posible aplicar one-hot encoding a los atributos discretos categóricos, esto aumentaría la dimensionalidad del dataset y podría generar problemas de performance. Pero aumentaría la interpretabilidad del modelo e inferir reglas basadas en categorías y no sobre el valor numérico de los atributos.\n",
    "\n",
    "- Dataset:\n",
    "\n",
    "    - **Oversampling de la clase minoritaria**: Creemos que es posible aplicar oversampling a la clase minoritaria, esto podría mejorar el desempeño de nuestro clasificador. De esta forma `train` tendría una proporción más equilibrada entre las clases. Luego, al momento de evaluar el modelo, utilizaremos `devel` y `test` como lo hemos hecho hasta ahora. Pero a diferencia de `train`, estos si tendrán una proporción desbalanceada, buscando así simular el comportamiento del modelo en un entorno real.\n",
    "\n",
    "- Algoritmo:\n",
    "\n",
    "    - **Incorporar nociones de look-ahead y backtracking**: Creemos que es posible incorporar nociones de look-ahead y backtracking para mejorar la calidad de las divisiones que realiza el algoritmo. Por ejemplo, si el algoritmo se encuentra en un nodo que tiene un atributo con muchos valores distintos, podría aplicar backtracking y buscar otro atributo para dividir el conjunto de entrenamiento. De esta forma, el algoritmo podría encontrar una mejor división que la que encontraría si se quedara en el nodo original. Aunque esto aumentaría la complejidad del algoritmo y ya no sería `ID3` puro. \n",
    "\n",
    "- Experimentación y Evaluación:\n",
    "\n",
    "    - Aplicar grid-search a los clasificadores de `scikit-learn`.\n",
    "    - No condicionar un \"ambiente justo\" para nuestros clasificadores, que compitan en igualdad de condiciones con los de `scikit-learn`.\n",
    "    - devel+test para evaluación final: Utilizar `devel` y `test` para evaluar el modelo final, así podemos tener más datos para evaluar el modelo, aunque `devel` ya se use en la etapa de experimentación.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
