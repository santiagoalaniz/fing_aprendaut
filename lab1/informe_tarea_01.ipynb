{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1, Grupo 02 - Arboles de decisión\n",
    "\n",
    "- Santiago Alaniz, 5082647-6, santiago.alaniz@fing.edu.uy\n",
    "- Bruno De Simone, 4914555-0, bruno.de.simone@fing.edu.uy\n",
    "- María Usuca, 4891124-3, maria.usuca@fing.edu.uy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Implementar un modelo que explique la deserción de estudiantes en la universidad.\n",
    " \n",
    "Se pide:\n",
    "\n",
    "- **(a)** Implementar una variante del algoritmo `ID3` agregandole los siguientes *hiperparametros*:\n",
    "    - **i)** `min_samples_split`: cantidad mínima de ejemplos para generar un nuevo nodo; en caso de que no se llegue a la cantidad requerida, se debe formar una hoja.\n",
    "    - **ii)** `min_split_gain`: ganancia mínima requerida para partir por un atributo; si ningún atributo llega a ese valor, se debe formar una hoja.\n",
    "- **(b)** Utilizar el algoritmo implementado en **(a)** para construir un arbol de decision, evaluar resultados utilizando el dataset provisto.\n",
    "- **(c)** Discuta como afecta la variacion de los hiperparametros con los modelos obtenidos.\n",
    "- **(d)** Corra los algoritmos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer` y compare los resultados.\n",
    "\n",
    "El dataset que vamos a considerar (con su debido preprocesamiento) es *Predict students dropout and accademic success* con **36 atributos y mas de 4000 instancias.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño\n",
    "\n",
    "El apartado de diseño engloba todas las decisiones que tomamos a la hora de cumplir con las subtareas planteadas en la seccion anterior. \n",
    "\n",
    "Podemos identificar las siguientes etapas:\n",
    "\n",
    "- **Carga de datos y Particionamiento**: Inicialización de los datos de los archivos CSV en un DataFrame de Pandas.\n",
    "- **Pre-procesamiento de datos**: Transformaciones necesarias para que los datos puedan ser utilizados por el modelo.\n",
    "- **Algoritmo**: Comentarios sobre la implementacion del algoritmo asi como las decisiones tomadas para su implementacion.\n",
    "- **Evaluacion**: Prueba del modelo con diferentes hiperparametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos y particionamiento\n",
    "\n",
    "En este apartado vamos a inicializar los datos siguiendo un esquema clásico de aprendizaje automático:\n",
    "\n",
    "- **Carga de datos**: Cargamos los datos desde el fichero `csv` y los almacenamos en un `DataFrame` de `pandas`.\n",
    "- **Particionamiento**: Particionamos los datos en dos conjuntos con `train_test_split` de `sklearn`.\n",
    "    - `train` para entrenar el modelo.\n",
    "    - `test` para evaluar el modelo.\n",
    "    - `test` para evaluar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = './assets/data.csv'\n",
    "SEED_NUMBER = 342\n",
    "TEST_SIZE   = 0.4\n",
    "DEVEL_SIZE  = 0.5\n",
    "\n",
    "data = pd.read_csv(CSV_PATH, sep=';')\n",
    "\n",
    "train, test = train_test_split(data, test_size= TEST_SIZE, random_state= SEED_NUMBER)\n",
    "test, devel = train_test_split(test, test_size= DEVEL_SIZE, random_state= SEED_NUMBER)\n",
    "\n",
    "train_indices   = set(train.index)\n",
    "devel_indices   = set(devel.index)\n",
    "test_indices    = set(test.index)\n",
    "\n",
    "assert len(train_indices.intersection(devel_indices)) == 0\n",
    "assert len(train_indices.intersection(test_indices)) == 0\n",
    "assert len(devel_indices.intersection(test_indices)) == 0\n",
    "\n",
    "print(f'<train: {train.shape[0]}, devel: {devel.shape[0]}, test: {test.shape[0]} >')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefinición de los valores del atributo objetivo `Target`.\n",
    "\n",
    "El atributo objetivo `Target` es un atributo categórico que indica el desenlace del estudiante en su vida académica. Este atributo tiene 3 posibles valores: \n",
    "\n",
    "- `Enrolled` (inscripto)\n",
    "- `Dropout` (abandono)\n",
    "- `Graduate` (graduado).\n",
    "\n",
    "La idea es construir un modelo sobre la diserción de los estudiantes, por lo que se decide agrupar los valores `Enrolled` y `Graduate` en un solo valor. \n",
    "\n",
    "-  0 &rarr; `Dropout`\n",
    "-  1 &rarr; `Enrolled` o `Graduate`\n",
    "\n",
    "**Nota**: \n",
    "La siguiente redefinición de atributos genera un desbalance en el atributo `Target`. De todas formas, continuaremos con el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, devel, test]:\n",
    "    df['Target'] = df['Target'].apply(lambda x: 0 if x == 'Dropout' else 1)\n",
    "\n",
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de atributos continuos.\n",
    "\n",
    "La [discretización](https://en.wikipedia.org/wiki/Data_binning) provee un mecanismo para particionar valores continuos en un número finito de valores discretos.\n",
    "\n",
    "De los [36 atributos presentes](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success) en el dataset, estos son listados como continuos:\n",
    "\n",
    "- `Previous qualification (grade)`\n",
    "- `Admission grade`\n",
    "- `Unemployment rate`\n",
    "- `Inflation rate`\n",
    "- `GDP`\n",
    "\n",
    "Para discretizar estos atributos, utlizaremos el modulo `scikit-learn.preprocessing`. \n",
    "\n",
    "En particular, la clase [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) con los siguientes parámetros:\n",
    "\n",
    "- `encode= 'ordinal'` (codificación de los bins) devuelve un array de enteros indicando a que bin pertenece cada valor.\n",
    "- `strategy='kmeans'` (estrategia de discretizacion) utiliza el algoritmo de [k-means](https://en.wikipedia.org/wiki/K-means_clustering) para determinar los bins. \n",
    "\n",
    "Finalmente, identificar estos atributos en el dataset es una tarea sencilla, ya que son los únicos del tipo `float64`.\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Hay un error en la [documentación de los datos](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success), figuran como discretos dos campos representados con `float64`:\n",
    "\n",
    "- `Curricular units 1st sem (grade)`\n",
    "- `Curricular units 2nd sem (grade)` \n",
    "\n",
    "Decidimos discretizarlos de todas formas, ya que algunas de las entradas tienen valores no enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "float64_cols = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for float64_col in float64_cols:\n",
    "    float64_discretizer = KBinsDiscretizer(subsample=None, encode='ordinal', strategy='kmeans')\n",
    "    train[[float64_col]]    = float64_discretizer.fit_transform(train[[float64_col]]).astype(int)\n",
    "    devel[[float64_col]]    = float64_discretizer.transform(devel[[float64_col]]).astype(int)\n",
    "    test[[float64_col]]     = float64_discretizer.transform(test[[float64_col]]).astype(int)\n",
    "\n",
    "train[float64_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario sobre el resto de los valores (discretos)\n",
    "\n",
    "Los valores discretos son ideales para `ID3` porque el algoritmo puede manejarlos directamente sin necesidad de transformaciones adicionales. Sin embargo, es crucial tener en cuenta el número de valores únicos que un atributo discreto puede tener.\n",
    "\n",
    "Somos conscientes que no existe un \"buen número\" de valores discretos distintos para un atributo en un árbol de decisión como ID3.\n",
    "Depende de varios factores, incluidos el tamaño del conjunto de datos, la complejidad del problema y el riesgo de sobreajuste. \n",
    "\n",
    "Además otro factor a tomar en cuenta es que los valores discretos pueden categorizar elementos complejos donde su valor numérico no tenga correlación con su valor semántico. Por ejemplo, la columna `Nationality` representa con un entero distintos países, si quisieramos categorizar ese valor de forma significativa tendríamos que construir supercategorías para los países (por ejemplo 0-Europa, 1-America, etc).\n",
    "\n",
    "Otra alternativa es aplicar [one-hot encoding](https://datagy.io/sklearn-one-hot-encode/) a los valores discretos, pero esto aumentaría la dimensionalidad del dataset y podría generar problemas de performance.\n",
    "\n",
    "La conclusión final es que el procesamiento de valores discretos es una tarea que excede el objetivo de este laboratorio, por eso decidimos no aplicar ningún preprocesamiento a los valores discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "int64_cols      = data.select_dtypes(include=['int64']).columns\n",
    "unique_values   = data[int64_cols].nunique()\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = unique_values.plot(kind='bar')\n",
    "plt.title('Valores Discretos')\n",
    "plt.xlabel('Atributos')\n",
    "plt.ylabel('Valores Distintos')\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "El algoritmo a desarrollar es `ID3` como se presento en el teórico, con la incorporación de ciertos meta-parametros que buscan evitar el sobreajuste del modelo.\n",
    "\n",
    "Para lograr este objetivo, se tuvo en consideración las siguientes subtareas:\n",
    "\n",
    "1. Sobre las variables/estructuras necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "2. `ID3_utils.py`: Un modulo con estructuras/funciones auxiliares para la implementación de `ID3`.\n",
    "3. `src.G02DecisionTrees.ID3Classifier`: Nuestro algoritmo inspirado en los clasificadores de `sklearn`.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre las variables necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "Para implementar `ID3` necesitamos definir las siguientes variables:\n",
    "\n",
    "Entradas:\n",
    "\n",
    "- `Examples`: conjunto de ejemplos de entrenamiento (`train`).\n",
    "- `Target_attribute`: atributo objetivo (`Target`).\n",
    "- `Attributes`: conjunto de atributos (el resto de las columnas).\n",
    "\n",
    "Estructura de Datos y Funciones Auxiliares:\n",
    "\n",
    "- `node`: estructura de datos que representa un nodo del arbol.\n",
    "- `max_gain_attr`: función que devuelve el atributo con mayor ganancia de información.\n",
    "- `attributes_values`: diccionario que mapea atributos con todos sus valores posibles.\n",
    "\n",
    "\n",
    "Para obtener `attributes_values` recorremos todos los atributos y obtenemos sus valores únicos. Hay que tener en cuenta que los atributos continuos fueron discretizados, por lo que sus valores son enteros que se encuentran en un rango acotado. (Preprocesamiento de atributos continuos).\n",
    "\n",
    "El resto de las Estrucutras de Datos y Funciones Auxiliares se encuentran en el modulo `ID3_utils.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "int64_cols      = data.select_dtypes(include=['int64']).columns\n",
    "attrs_values    = {attr: sorted(data[attr].unique()) for attr in int64_cols}\n",
    "float64_cols    = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "attrs_values.update({col: list(range(5)) for col in float64_cols})\n",
    "\n",
    "print(f'attrs: {len(attrs_values.keys())}, Algunos valores de atributos discretos: \\n')\n",
    "for k in list(attrs_values.keys())[:5]: print(f\"{k}: {attrs_values[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ID3_utils.py`: Un módulo con estructuras/funciones auxiliares para la implementacion de `ID3`.\n",
    "\n",
    "Este módulo de Python está diseñado para implementar árboles de decisión utilizando el algoritmo ID3. A continuación se describen los componentes principales:\n",
    "\n",
    "- `ID3Node`: Esta es una clase que representa un nodo en el árbol de decisión. Cada nodo tiene una etiqueta (`label`) que indica el atributo que se está evaluando en ese nodo, y una ganancia de información (`info_gain`) que indica cuánta incertidumbre se reduce al dividir el conjunto de datos según ese atributo.\n",
    "- `node`: Esta es una función auxiliar que facilita la creación de nuevos nodos. Acepta una etiqueta y una ganancia de información como argumentos y devuelve una instancia de `ID3Node`.\n",
    "- `entropy`: Esta función calcula la entropía de un conjunto de datos dado un atributo objetivo (`attr_tget`). La entropía es una medida de la incertidumbre o el desorden en los datos.\n",
    "- `max_gain_attr`: Esta función determina qué atributo tiene la máxima ganancia de información cuando se utiliza para evaluar el mejor nodo candidato.\n",
    "- `evaluate`: Esta función evalúa un conjunto de datos y busca en el árbol de decisión para determinar la clase de cada ejemplo. Devuelve una lista de predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ID3_utils import max_gain_attr, node\n",
    "\n",
    "attr, gain  = max_gain_attr(train, 'Target', attrs_values)\n",
    "id3_node    = node(attr, info_gain= gain)\n",
    "\n",
    "id3_node.children[attrs_values[attr][0]] = node('Nationality', 0.02)\n",
    "\n",
    "print(f\"node: {id3_node.label, id3_node.info_gain, id3_node.children}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `src.G02DecisionTrees.ID3Classifier`: Nuestro clase-clasificadora inspirada en `sklearn`.\n",
    "\n",
    "Nuestro algoritmo esta encapsulado en una clase clasificadora que está diseñada/inspirada en base a los clasificadores de `scikit-learn`.\n",
    "La principal motivacion para hacerlo de esta forma es el objetivo de comparar los resultados de nuestro algoritmo con los de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "\n",
    "Entonces, consideramos acertado modelar esta clase como si se tratara de una clase más de `scikit-learn.`\n",
    "\n",
    "**Clase ID3Classifier**: Define el clasificador ID3.\n",
    "\n",
    "- `__init__`: Inicializa el clasificador con los meta-parametros. \n",
    "  - `min_samples_split` y `min_split_gain`: requeridas por la letra del obligatorio, limitan el crecimiento del arbol. \n",
    "  - `attr_values`, `attrs` necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "`ID3Classifier` implemeneta funciones típicas de `scikit-learn`:\n",
    "\n",
    "- El método `fit` toma un DataFrame `X`, una serie `y` como entrada y construye un árbol de decisión con `_id3`.\n",
    "- El método `predict` utiliza el árbol para hacer predicciones en un nuevo conjunto de datos.\n",
    "- El método `score` evalúa la precisión del modelo utilizando `scikit-learn.accuracy_score`.\n",
    "    \n",
    "**`__id3`** implementa el algoritmo recursivamente para construir el árbol de decisión.\n",
    "\n",
    "```python\n",
    "## Mitchell, p. 68\n",
    "def __id3(self, exs, attr_tget, attrs):\n",
    "    same_value_attr_tget = exs[attr_tget].nunique() == 1\n",
    "    attrs_empty = len(attrs) == 0\n",
    "    \n",
    "    if same_value_attr_tget or attrs_empty: return utils.node(exs[attr_tget].mode()[0])\n",
    "\n",
    "    _attrs_values = { k: self.attrs_values[k] for k in attrs }\n",
    "    best_attr, gain = utils.max_gain_attr(exs, attr_tget, _attrs_values)\n",
    "    \n",
    "    if gain <= self.min_split_gain: return utils.node(exs[attr_tget].mode()[0])\n",
    "    \n",
    "    node = utils.node(best_attr, gain)\n",
    "    best_attr_values = self.attrs_values[best_attr]\n",
    "    \n",
    "    for attr_val in best_attr_values:\n",
    "        exs_i = exs[exs[best_attr] == attr_val]\n",
    "\n",
    "        if exs_i.shape[0] <= self.min_samples_split: \n",
    "          node.children[attr_val] = utils.node(exs[attr_tget].mode()[0])\n",
    "        else:\n",
    "          attrs_i = [attr for attr in attrs if attr != best_attr]\n",
    "          node.children[attr_val] = self.__id3(exs_i, attr_tget, attrs_i)\n",
    "    \n",
    "    return node\n",
    "```\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Vamos a modificar la columna `Target`  de `train` para forzar la creacion de un ***`dummy classifier`***. En particular uno que siempre prediga `1` (inscripto o graduado). Obtendriamos un arbol de decision con un solo nodo hoja valor 1, como esta clase esta desbalanceada favorablemente, tendremos un accuracy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.G02_decision_trees import ID3Classifier\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']), devel['Target']\n",
    "\n",
    "G02_dumb_clf = ID3Classifier(attrs_values= attrs_values)\n",
    "G02_dumb_clf.fit(train_X, train_y.apply(lambda x: 1))\n",
    "\n",
    "print(f'{G02_dumb_clf.tree} [\\\n",
    " label: {G02_dumb_clf.tree.label},\\\n",
    " info_gain: {G02_dumb_clf.tree.info_gain},\\\n",
    " children: {G02_dumb_clf.tree.children} ]'\n",
    ")\n",
    "\n",
    "G02_dumb_clf.score(devel_X, devel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación\n",
    "\n",
    "Como se nos ha comentado en el teorico, la evaluación de un modelo es una tarea compleja que requiere de un análisis profundo de los resultados obtenidos.\n",
    "En particular, la seleccion de metricas acorde al problema a resolver es una tarea que requiere de un conocimiento profundo del dominio.\n",
    "\n",
    "Sabemos que el dataset que estamos analizando tiene un desbalance en el atributo objetivo `Target`, por lo que la métrica de `accuracy` no es la más adecuada para evaluar el modelo. Por ejemplo un modelo que siempre prediga un resultado con el valor de una clase favorable, tendra un accuracy elevado (`G02_dumb_clf`) \n",
    "\n",
    "Vamos a utilizar la metrica [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) para evaluar el modelo, es adecuada para problemas con clases desbalanceadas.\n",
    "\n",
    "Como ya comentamos anteriormente, nuestro equipo convenientemente separó los datos en tres conjuntos:\n",
    "\n",
    "- `train`: para entrenar el modelo.\n",
    "- `devel`: para ajustar los hiperparametros y evaluaciones intermedias.\n",
    "- `test`: para evaluar el modelo final.\n",
    "\n",
    "Se utilizo una proporcion 60/20/20 para los conjuntos `train`, `devel` y `test` respectivamente. Estos conjuntos ademas se encuentran mezclados de forma aleatoria y estraficados, de forma tal que la proporcion de clases sea la misma en los tres conjuntos.\n",
    "\n",
    "***Nota***:\n",
    "\n",
    "Impremiremos esta proporcion para dejar constancia. De la documentacion de `sklearn.model_selection.train_test_split` se desprende que la estratificacion es un comportamiento predeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_proportion = train_y.value_counts(normalize=True)\n",
    "devel_target_proportion = devel_y.value_counts(normalize=True)\n",
    "\n",
    "print(f'Train: {train_target_proportion}\\n')\n",
    "print(f'Devel: {devel_target_proportion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación\n",
    "\n",
    "En este apartado vamos a realizar una serie de experimentos.\n",
    "\n",
    "- Busqueda con Grid Search para encontrar los mejores hiperparametros de nuestro modelo.\n",
    "- Definicion de nuestro modelo final.\n",
    "- Exploracion de los modelos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "- Comparativa final de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search para encontrar los mejores hiperparametros de nuestro modelo.\n",
    "\n",
    "Para encontrar la mejor combinacion de meta-parametros para nuestro clasificador vamos a utilizar Grid Search. \n",
    "\n",
    "Primero vamos a definir un espacion de busqueda tomando ciertas precauciones. La idea de los meta-parametros es evitar el sobreajuste del modelo, sin estos elementos, un arbol de decision puede crecer hasta tener un nodo por cada ejemplo de entrenamiento. \n",
    "\n",
    "Por ende, un arbol con muchos nodos es un arbol que esta sobreajustado. De forma analoga, tampoco queremos un arbol que solo tenga un nodo, como el `G02_dumb_clf` que siempre predice `1`.\n",
    "\n",
    "Sabemos que:\n",
    "\n",
    "- `min_samples_split` &rarr; cantidad mínima de ejemplos para generar un nuevo nodo.\n",
    "- `min_split_gain` &rarr; ganancia mínima requerida para partir por un atributo.\n",
    "\n",
    "No satisfacer estas condiciones fuerza la creacion de un nodo hoja con el valor mas comun del atributo objetivo `Target`.\n",
    "\n",
    "Definimos el espacio de busqueda de la siguiente forma:\n",
    "\n",
    "- `min_samples_split` &rarr; (0, 885)\n",
    "- `min_split_gain` &rarr; (0.0, 0.325):\n",
    "\n",
    "En cada iteracion de `ID3` el conjunto de entrenamiento se reduce en factor de cuantos ejemplos habia para el valor del atributo pivotal. Por ejemplo, si el atributo pivotal es `Nationality` y el valor es `Uruguay`, entonces el conjunto de entrenamiento se reduce a los ejemplos que tienen `Nationality == Uruguay`. \n",
    "\n",
    "En resumen, el conjunto de ejemplos se reduce en factor del valor del atributo pivotal. `devel` tiene 885 ejemplos, es decir un 20% de los ejemplos de `train`. Nuestro metodo de grid search va a iterar entre el 0% y el 20% de la cantidad total de ejemplos de `train`.\n",
    "\n",
    "El limite superior surge de la ganancia maxima de un atributo en todo `train`. El limite inferior es 0.0 porque es el valor predeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ID3_utils import max_gain_attr\n",
    "from src.G02_decision_trees import ID3Classifier\n",
    "from sklearn.metrics import f1_score\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "GRID_SAMPLES = 10\n",
    "\n",
    "attr, gain = max_gain_attr(train, 'Target', attrs_values)\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']), devel['Target']\n",
    "\n",
    "meta_params_grid = {\n",
    "    'min_samples_split': np.linspace(devel.shape[0], 2, GRID_SAMPLES).astype(int),\n",
    "    'min_split_gain': np.linspace(gain, 0.0, GRID_SAMPLES)\n",
    "}\n",
    "\n",
    "def grid_search_to_csv():\n",
    "    results = pd.DataFrame(columns=['f1_score', 'min_samples_split', 'min_split_gain'])\n",
    "\n",
    "    for mss_i in meta_params_grid['min_samples_split']:\n",
    "        for msg_j in meta_params_grid['min_split_gain']:\n",
    "            clf = ID3Classifier(attrs_values=attrs_values, min_samples_split= mss_i, min_split_gain= msg_j)\n",
    "            clf.fit(train_X, train_y)\n",
    "            results.loc[len(results)] = [f1_score(devel_y, clf.predict(devel_X)), mss_i, msg_j]\n",
    "\n",
    "    results.to_csv('assets/grid_search.csv', index=False)\n",
    "\n",
    "if not os.path.exists('assets/grid_search.csv'): grid_search_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de nuestro modelo final.\n",
    "\n",
    "Despues de evaluar 100 modelos con grid search, construimos un `CSV` con los resultados obtenidos.\n",
    "\n",
    "- `grid_search.csv`: Resultados de la busqueda con grid search.\n",
    "\n",
    "Vamos a utilizar `pandas` para obtener el promedio de los meta-parametros que obtuvieron el mejor `f1_score`.\n",
    "\n",
    "Obteniendo asi los meta-parametros para nuestro modelo final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.G02_decision_trees import ID3Classifier\n",
    "\n",
    "grid_search = pd.read_csv('assets/grid_search.csv')\n",
    "\n",
    "max_f1_score = grid_search['f1_score'].max()\n",
    "best_params = grid_search[grid_search['f1_score'] == max_f1_score].iloc[0]\n",
    "\n",
    "max_min_samples_split = best_params['min_samples_split'].mean().astype(int)\n",
    "max_min_split_gain = best_params['min_split_gain'].mean()\n",
    "\n",
    "G02_best_clf = ID3Classifier(attrs_values=attrs_values, min_samples_split=max_min_samples_split,\n",
    "                             min_split_gain=max_min_split_gain)\n",
    "\n",
    "G02_best_clf.fit(train_X, train_y)\n",
    "\n",
    "print(f'f1_score(devel): {f1_score(devel_y, G02_best_clf.predict(devel_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion de los clasificadores `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "\n",
    "Vamos a indagar en los siguientes clasificadores `scikit-learn DecisionTreeClassifier, RandomForestClassifer`. Sobre todo manipular sus metaprametros para que, en la medida de lo posible, nuestro mejor clasificador compita con ellos en igualdad de condiciones.\n",
    "\n",
    "Por igualdad de condiciones nos referimos a las siguientes consideraciones:\n",
    "\n",
    "- **Metaparametros**: Utilizar los mismos metaparametros que nuestro mejor clasificador. De no encontrar/detectar un metaparametro equivalente, utilizar el valor por defecto.\n",
    "- **Entreanamiento**: Utilizar el mismo conjunto de entrenamiento que nuestro mejor clasificador.\n",
    "- **Evaluacion**: Utilizar la misma metrica de evaluacion que nuestro mejor clasificador.\n",
    "\n",
    "Tomamos estas consideraciones porque asumimos que los clasificadores de `scikit-learn` son robustos y estan optimizados para obtener los mejores resultados posibles.\n",
    "\n",
    "#### `scikit-learn DecisionTreeClassifier`\n",
    "\n",
    "Identificamos los siguientes metaparametros:\n",
    "\n",
    "- `criterion`: La funcion para medir la calidad de una particion. Utilizamos `entropy` porque es la misma que utiliza nuestro clasificador.\n",
    "- `min_samples_split`: Su definicion es la misma que la de nuestro clasificador. Utilizamos el valor de nuestro mejor clasificador que casualmente es el valor por defecto.\n",
    "\n",
    "No existe un metaparametro equivalente a `min_split_gain`.\n",
    "\n",
    "#### `scikit-learn RandomForestClassifer`\n",
    "\n",
    "De forma similar al clasificador anterior, identificamos los siguientes metaparametros:\n",
    "\n",
    "- `criterion`: analogo al clasificador anterior, utilizamos `entropy`.\n",
    "- `min_samples_split`: analogo al clasificador anterior, utilizamos el valor por defecto.\n",
    "\n",
    "No existe un metaparametro equivalente a `min_split_gain`.\n",
    "\n",
    "En resumen, los clasificadores que consideramos mas cercanos a nuestro mejor clasificador son:\n",
    "\n",
    "- `DecisionTreeClassifier` con `criterion='entropy'` y `min_samples_split=2`.\n",
    "- `RandomForestClassifer` con `criterion='entropy'` y `min_samples_split=2`.\n",
    "\n",
    "***Nota***:\n",
    "\n",
    "Hay un parametro llamado `min_impurity_decrease` que es similar a `min_split_gain`, es una formula que aplica tecnicas de look-ahead para determinar si un nodo debe ser dividido. Dado que nuestro clasificador es puramente greedy, no tiene sentido utilizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']) , devel['Target']\n",
    "\n",
    "fair_dt_clf = DecisionTreeClassifier(criterion= 'entropy')\n",
    "fair_dt_clf.fit(train_X, train_y)\n",
    "\n",
    "fair_rf_clf = RandomForestClassifier(criterion= 'entropy')\n",
    "fair_rf_clf.fit(train_X, train_y)\n",
    "\n",
    "print(f'DecisionTreeClassifier f1_score(devel): {f1_score(devel_y, fair_dt_clf.predict(devel_X))}')\n",
    "print(f'RandomForestClassifier f1_score(devel): {f1_score(devel_y, fair_rf_clf.predict(devel_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa final de los modelos.\n",
    "\n",
    "En este apartado vamos a comparar el desempeño de los modelos que hemos construido. Recordemos brevemente cuales son:\n",
    "\n",
    "- `G02_dumb_clf`: Un clasificador que siempre predice `1` (inscripto o graduado).\n",
    "- `G02_best_clf`: Nuestro mejor clasificador con los meta-parametros que obtuvieron el mejor `f1_score`.\n",
    "- `fair_dt_clf`: `DecisionTreeClassifier` con `criterion='entropy'`.\n",
    "- `fair_rf_clf`: `RandomForestClassifer` con `criterion='entropy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = test.drop(columns=['Target']), test['Target']\n",
    "\n",
    "print(f'DecisionTreeClassifier  f1_score(test): {f1_score(test_y, fair_dt_clf.predict(test_X))}')\n",
    "print(f'RandomForestClassifier  f1_score(test): {f1_score(test_y, fair_rf_clf.predict(test_X))}')\n",
    "print(f'Best ID3Classifier      f1_score(test): {f1_score(test_y, G02_best_clf.predict(test_X))}')\n",
    "print(f'Dumb ID3Classifier      f1_score(test): {f1_score(test_y, G02_dumb_clf.predict(test_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
    "- ¿cuándo se dieron los mejores resultados del jugador?\n",
    "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
    "- ¿cómo mejoraría los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosas de bruno (posiblemente desactualizado ☠️⚰️)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from src.G02_algorithm import CustomID3Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, y_train = train.drop(columns=['Target']), train['Target']\n",
    "\n",
    "custom_clf = CustomID3Classifier(MIN_SAMPLES_SPLIT=0, MIN_SPLIT_GAIN=0)\n",
    "custom_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.drop(columns=['Target']), test['Target']\n",
    "predictions = custom_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f')\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular matrices de confusión\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "cm_random_forest = confusion_matrix(y_test, y_pred_random_forest)\n",
    "\n",
    "## Crear objetos ConfusionMatrixDisplay\n",
    "cmd_decision_tree = ConfusionMatrixDisplay(confusion_matrix=cm_decision_tree, display_labels=decision_tree_clf.classes_)\n",
    "cmd_random_forest = ConfusionMatrixDisplay(confusion_matrix=cm_random_forest, display_labels=random_forest_clf.classes_)\n",
    "\n",
    "# Mostrar las matrices de confusión\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "cmd_decision_tree.plot(cmap=plt.cm.Blues, ax=axes[0])\n",
    "axes[0].set_title(\"Matriz de Confusión - Decision Tree\")\n",
    "\n",
    "cmd_random_forest.plot(cmap=plt.cm.Blues, ax=axes[1])\n",
    "axes[1].set_title(\"Matriz de Confusión - Random Forest\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
