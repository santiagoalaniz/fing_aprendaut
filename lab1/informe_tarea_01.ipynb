{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1, Grupo 02 - Arboles de decisión\n",
    "\n",
    "- Santiago Alaniz, 5082647-6, santiago.alaniz@fing.edu.uy\n",
    "- Bruno De Simone, 4914555-0, bruno.de.simone@fing.edu.uy\n",
    "- María Usuca, 4891124-3, maria.usuca@fing.edu.uy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Implementar un modelo que explique la deserción de estudiantes en la universidad.\n",
    " \n",
    "Se pide:\n",
    "\n",
    "- **(a)** Implementar una variante del algoritmo `ID3` agregandole los siguientes *hiperparametros*:\n",
    "    - **i)** `min_samples_split`: cantidad mínima de ejemplos para generar un nuevo nodo; en caso de que no se llegue a la cantidad requerida, se debe formar una hoja.\n",
    "    - **ii)** `min_split_gain`: ganancia mínima requerida para partir por un atributo; si ningún atributo llega a ese valor, se debe formar una hoja.\n",
    "- **(b)** Utilizar el algoritmo implementado en **(a)** para construir un arbol de decision, evaluar resultados utilizando el dataset provisto.\n",
    "- **(c)** Discuta como afecta la variacion de los hiperparametros con los modelos obtenidos.\n",
    "- **(d)** Corra los algoritmos de `scikit-learn` DecisionTreeClassifier, RandomForestClassifer y compare los resultados.\n",
    "\n",
    "El dataset que vamos a considerar (con su debido preprocesamiento) es *Predict students dropout and accademic success* con **36 atributos y mas de 4000 instancias.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño\n",
    "\n",
    "El apartado de diseño engloba todas las decisiones que tomamos a la hora de cumplir con las subtareas planteadas en la seccion anterior. \n",
    "\n",
    "Podemos identificar las siguientes etapas:\n",
    "\n",
    "- **Carga de datos y Particionamiento**: Inicialización de los datos de los archivos CSV en un DataFrame de Pandas.\n",
    "- **Pre-procesamiento de datos**: Transformaciones necesarias para que los datos puedan ser utilizados por el modelo.\n",
    "- **Algoritmo**: Comentarios sobre la implementacion del algoritmo asi como las decisiones tomadas para su implementacion.\n",
    "- **Evaluacion**: Prueba del modelo con diferentes hiperparametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos y particionamiento\n",
    "\n",
    "En este apartado vamos a inicializar los datos siguiendo un esquema clásico de aprendizaje automático:\n",
    "\n",
    "- **Carga de datos**: Cargamos los datos desde el fichero `csv` y los almacenamos en un `DataFrame` de `pandas`.\n",
    "- **Particionamiento**: Particionamos los datos en dos conjuntos con `train_test_split` de `sklearn`.\n",
    "    - `train` para entrenar el modelo.\n",
    "    - `devel` para evaluar el modelo.\n",
    "    - `test` para evaluar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = './assets/data.csv'\n",
    "SEED_NUMBER = 42069\n",
    "\n",
    "TEST_SIZE = 0.4\n",
    "DEVEL_SIZE = 0.5\n",
    "\n",
    "data = pd.read_csv(CSV_PATH, sep=';')\n",
    "train, test = train_test_split(data, test_size= TEST_SIZE, random_state= SEED_NUMBER)\n",
    "test, devel = train_test_split(train, test_size= DEVEL_SIZE, random_state= SEED_NUMBER)\n",
    "\n",
    "print(f'< data: {data.shape[0]} >')\n",
    "print(f'< train: {train.shape[0]}, devel: {devel.shape[0]}, test: {test.shape[0]} >')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de los datos\n",
    "\n",
    "Para el preprocesado de los datos tomaremos en cuenta los siguientes puntos:\n",
    "\n",
    "- Redefinicion de los valores del atributo objetivo `Target` para que sean 0 y 1.\n",
    "- Preprocesamiento de atributos continuos.\n",
    "- Comentario sobre el resto de los valores (discretos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefinicion de los valores del atributo objetivo `Target`.\n",
    "\n",
    "El atributo objetivo `Target` es un atributo categórico que indica el desenlace del estudiante en su vida académica. Este atributo tiene 3 posibles valores: \n",
    "\n",
    "- `Enrolled` (inscripto)\n",
    "- `Dropout` (abandono)\n",
    "- `Graduate` (graduado).\n",
    "\n",
    "La idea es construir un modelo sobre la diserción de los estudiantes, por lo que se decide agrupar los valores `Enrolled` y `Graduate` en un solo valor. \n",
    "\n",
    "-  0 &rarr; `Dropout`\n",
    "-  1 &rarr; `Enrolled` o `Graduate`\n",
    "\n",
    "**Nota**: \n",
    "La siguiente redefinición de atributos genera un desbalance en el atributo `Target`. De todas formas, continuaremos con el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, devel, test]:\n",
    "    df['Target'] = df['Target'].apply(lambda x: 0 if x == 'Dropout' else 1)\n",
    "\n",
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de atributos continuos.\n",
    "\n",
    "La [discretizacion](https://en.wikipedia.org/wiki/Data_binning) provee un mecanismo para particionar valores continuos en un numero finito de valores discretos.\n",
    "\n",
    "De los [36 atributos presentes](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success) en el dataset, estos son listados como continuos:\n",
    "\n",
    "- `Previous qualification (grade)`\n",
    "- `Admission grade`\n",
    "- `Unemployment rate`\n",
    "- `Inflation rate`\n",
    "- `GDP`\n",
    "\n",
    "Para discretizar estos atributos, utlizaremos el modulo `scikit-learn.preprocessing`. \n",
    "\n",
    "En particular, la clase [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) con los siguientes parametros:\n",
    "\n",
    "- `encode= 'ordinal'` (codificacion de los bins) devuelve un array de enteros indicando a que bin pertenece cada valor.\n",
    "- `strategy='kmeans'` (estrategia de discretizacion) utiliza el algoritmo de [k-means](https://en.wikipedia.org/wiki/K-means_clustering) para determinar los bins. \n",
    "\n",
    "Finalmente, identificar estos atributos en el dataset es una tarea sencilla, ya que son los unicos del tipo `float64`.\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Hay un error en la [documentación de los datos](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success), figuran como discretos dos campos representados con `float64`:\n",
    "\n",
    "- `Curricular units 1st sem (grade)`\n",
    "- `Curricular units 2nd sem (grade)` \n",
    "\n",
    "Decidimos discretizarlos de todas formas, ya que algunas de las entradas tienen valores no enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "float64_cols = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for float64_col in float64_cols:\n",
    "    float64_col_discretizer = KBinsDiscretizer(subsample=None, encode='ordinal', strategy='kmeans')\n",
    "    train[[float64_col]] = float64_col_discretizer.fit_transform(train[[float64_col]]).astype(int)\n",
    "    devel[[float64_col]] = float64_col_discretizer.transform(devel[[float64_col]]).astype(int)\n",
    "    test[[float64_col]] = float64_col_discretizer.transform(test[[float64_col]]).astype(int)\n",
    "\n",
    "train[float64_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario sobre el resto de los valores (discretos)\n",
    "\n",
    "Los valores discretos son ideales para `ID3` porque el algoritmo puede manejarlos directamente sin necesidad de transformaciones adicionales. Sin embargo, es crucial tener en cuenta el número de valores únicos que un atributo discreto puede tener.\n",
    "\n",
    "Somos conscientes que no existe un \"buen número\" de valores discretos distintos para un atributo en un árbol de decisión como ID3.\n",
    "Depende de varios factores, incluidos el tamaño del conjunto de datos, la complejidad del problema y el riesgo de sobreajuste. \n",
    "\n",
    "Ademas otro factor a tomar en cuenta es que los valores discretos pueden categorizar elementos complejos donde su valor numerico no tenga correlacion con su valor semantico. Por ejemplo, la columna `Nationality` representa con un entero distintos paises, si quisieramos categorizar ese valor de forma significativa tendriamos que construir supercategorias para los paises (por ejemplo 0-Europa, 1-America, etc).\n",
    "\n",
    "Sin dudas lo anterior volveria el procesamiento una tarea que excede el objetivo de este laboratorio, por eso decidimos no aplicar ningu preprocesamiento a los valores discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "int64_cols = data.select_dtypes(include=['int64']).columns\n",
    "unique_values =  data[int64_cols].nunique()\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = unique_values.plot(kind='bar')\n",
    "plt.title('Valores Discretos')\n",
    "plt.xlabel('Atributos')\n",
    "plt.ylabel('Valores Distintos')\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "El algoritmo a desarrollar es `ID3` como se presento en el teórico, con la incorporacion de ciertos meta-parametros que buscan evitar el sobreajuste del modelo.\n",
    "\n",
    "Para lograr este objetivo, se tuvo en consideracion las siguientes subtareas:\n",
    "\n",
    "1. Sobre las variables/estructuras necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "2. `ID3_utils.py`: Un modulo con estructuras/funciones auxiliares para la implementacion de `ID3`.\n",
    "3. Pseudocodigo del algoritmo `ID3` implementado.\n",
    "3. `src.G02DecisionTrees.ID3Classifier`: Un diseño modular del algoritmo inspirado en `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre las variables necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "Para implementar `ID3` necesitamos definir las siguientes variables:\n",
    "\n",
    "Entradas:\n",
    "\n",
    "- `Examples`: conjunto de ejemplos de entrenamiento (`train`).\n",
    "- `Target_attribute`: atributo objetivo (`Target`).\n",
    "- `Attributes`: conjunto de atributos (el resto de las columnas).\n",
    "\n",
    "Estructura de Datos y Funciones Auxiliares:\n",
    "\n",
    "- `node`: estructura de datos que representa un nodo del arbol.\n",
    "- `max_gain_attr`: funcion que devuelve el atributo con mayor ganancia de informacion.\n",
    "- `attributes_values`: diccionario que mapea atributos con tods sus valores posibles.\n",
    "\n",
    "\n",
    "Para obtener `attributes_values` recorremos todos los atributos y obtenemos sus valores unicos. Hay que tener en cuenta que los atributos continuos fueron discretizados, por lo que sus valores son enteros que se encuentran en un rango acotado. (Preprocesamiento de atributos continuos).\n",
    "\n",
    "El resto de las Estrucutras de Datos y Funciones Auxiliares se encuentran en el modulo `ID3_utils.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "int64_cols = data.select_dtypes(include=['int64']).columns\n",
    "attrs_values = {attr: sorted(data[attr].unique()) for attr in int64_cols}\n",
    "float64_cols = data.select_dtypes(include=['float64']).columns\n",
    "attrs_values.update({col: list(range(5)) for col in float64_cols})\n",
    "\n",
    "for k in list(attrs_values.keys())[:5]: print(f\"{k}: {attrs_values[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Evaluación\n",
    "- Qué conjunto de métricas se utilizan para la evaluación de la solución y su definición\n",
    "- Sobre qué conjunto(s) se realiza el entrenamiento, ajuste de la solución, evaluación, etc. Explicar cómo se construyen estos conjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación\n",
    "\n",
    "- Presentar los distintos experimentos que se realizan y los resultados que se obtienen.\n",
    "\n",
    "- La información de los resultados se presenta en tablas y en gráficos, de acuerdo a su naturaleza. Por ejemplo:\n",
    "\n",
    "_En la gráfica 1, se observa el error cuadrático total del conjunto de entrenamiento a medida que pasan los juegos para el oponente X_\n",
    "\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier(min_samples_split = MIN_SAMPLES_SPLIT, \\\n",
    "                                           max_leaf_nodes = MAX_LEAF_NODES)\n",
    "decision_tree_clf.fit(X_train, y_train)\n",
    "y_pred_decision_tree = decision_tree_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_decision_tree)\n",
    "print(\"Precisión del modelo DT:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecución de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(min_samples_split = MIN_SAMPLES_SPLIT, \\\n",
    "                                        max_leaf_nodes = MAX_LEAF_NODES)\n",
    "random_forest_clf.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_random_forest)\n",
    "print(\"Precisión del modelo RF:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
    "- ¿cuándo se dieron los mejores resultados del jugador?\n",
    "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
    "- ¿cómo mejoraría los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosas de bruno (posiblemente desactualizado ☠️⚰️)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from src.G02_algorithm import CustomID3Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, y_train = train.drop(columns=['Target']), train['Target']\n",
    "\n",
    "custom_clf = CustomID3Classifier(MIN_SAMPLES_SPLIT=0, MIN_SPLIT_GAIN=0)\n",
    "custom_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.drop(columns=['Target']), test['Target']\n",
    "predictions = custom_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f')\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular matrices de confusión\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "cm_random_forest = confusion_matrix(y_test, y_pred_random_forest)\n",
    "\n",
    "## Crear objetos ConfusionMatrixDisplay\n",
    "cmd_decision_tree = ConfusionMatrixDisplay(confusion_matrix=cm_decision_tree, display_labels=decision_tree_clf.classes_)\n",
    "cmd_random_forest = ConfusionMatrixDisplay(confusion_matrix=cm_random_forest, display_labels=random_forest_clf.classes_)\n",
    "\n",
    "# Mostrar las matrices de confusión\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "cmd_decision_tree.plot(cmap=plt.cm.Blues, ax=axes[0])\n",
    "axes[0].set_title(\"Matriz de Confusión - Decision Tree\")\n",
    "\n",
    "cmd_random_forest.plot(cmap=plt.cm.Blues, ax=axes[1])\n",
    "axes[1].set_title(\"Matriz de Confusión - Random Forest\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
