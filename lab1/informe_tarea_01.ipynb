{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1, Grupo 02 - Arboles de decisión\n",
    "\n",
    "- Santiago Alaniz, 5082647-6, santiago.alaniz@fing.edu.uy\n",
    "- Bruno De Simone, 4914555-0, bruno.de.simone@fing.edu.uy\n",
    "- María Usuca, 4891124-3, maria.usuca@fing.edu.uy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Implementar un modelo que explique la deserción de estudiantes en la universidad.\n",
    " \n",
    "Se pide:\n",
    "\n",
    "- **(a)** Implementar una variante del algoritmo `ID3` agregandole los siguientes *hiperparametros*:\n",
    "    - **i)** `min_samples_split`: cantidad mínima de ejemplos para generar un nuevo nodo; en caso de que no se llegue a la cantidad requerida, se debe formar una hoja.\n",
    "    - **ii)** `min_split_gain`: ganancia mínima requerida para partir por un atributo; si ningún atributo llega a ese valor, se debe formar una hoja.\n",
    "- **(b)** Utilizar el algoritmo implementado en **(a)** para construir un arbol de decision, evaluar resultados utilizando el dataset provisto.\n",
    "- **(c)** Discuta como afecta la variacion de los hiperparametros con los modelos obtenidos.\n",
    "- **(d)** Corra los algoritmos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer` y compare los resultados.\n",
    "\n",
    "El dataset que vamos a considerar (con su debido preprocesamiento) es *Predict students dropout and accademic success* con **36 atributos y mas de 4000 instancias.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño\n",
    "\n",
    "El apartado de diseño engloba todas las decisiones que tomamos a la hora de cumplir con las subtareas planteadas en la seccion anterior. \n",
    "\n",
    "Podemos identificar las siguientes etapas:\n",
    "\n",
    "- **Carga de datos y Particionamiento**: Inicialización de los datos de los archivos CSV en un DataFrame de Pandas.\n",
    "- **Pre-procesamiento de datos**: Transformaciones necesarias para que los datos puedan ser utilizados por el modelo.\n",
    "- **Algoritmo**: Comentarios sobre la implementacion del algoritmo asi como las decisiones tomadas para su implementacion.\n",
    "- **Evaluacion**: Prueba del modelo con diferentes hiperparametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos y particionamiento\n",
    "\n",
    "En este apartado vamos a inicializar los datos siguiendo un esquema clásico de aprendizaje automático:\n",
    "\n",
    "- **Carga de datos**: Cargamos los datos desde el fichero `csv` y los almacenamos en un `DataFrame` de `pandas`.\n",
    "- **Particionamiento**: Particionamos los datos en dos conjuntos con `train_test_split` de `sklearn`.\n",
    "    - `train` para entrenar el modelo.\n",
    "    - `test` para evaluar el modelo.\n",
    "    - `test` para evaluar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = './assets/data.csv'\n",
    "SEED_NUMBER = 342\n",
    "TEST_SIZE   = 0.4\n",
    "DEVEL_SIZE  = 0.5\n",
    "\n",
    "data = pd.read_csv(CSV_PATH, sep=';')\n",
    "\n",
    "train, test = train_test_split(data, test_size= TEST_SIZE, random_state= SEED_NUMBER)\n",
    "test, devel = train_test_split(test, test_size= DEVEL_SIZE, random_state= SEED_NUMBER)\n",
    "\n",
    "train_indices   = set(train.index)\n",
    "devel_indices   = set(devel.index)\n",
    "test_indices    = set(test.index)\n",
    "\n",
    "assert len(train_indices.intersection(devel_indices)) == 0\n",
    "assert len(train_indices.intersection(test_indices)) == 0\n",
    "assert len(devel_indices.intersection(test_indices)) == 0\n",
    "\n",
    "print(f'<train: {train.shape[0]}, devel: {devel.shape[0]}, test: {test.shape[0]} >')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefinición de los valores del atributo objetivo `Target`.\n",
    "\n",
    "El atributo objetivo `Target` es un atributo categórico que indica el desenlace del estudiante en su vida académica. Este atributo tiene 3 posibles valores: \n",
    "\n",
    "- `Enrolled` (inscripto)\n",
    "- `Dropout` (abandono)\n",
    "- `Graduate` (graduado).\n",
    "\n",
    "La idea es construir un modelo sobre la diserción de los estudiantes, por lo que se decide agrupar los valores `Enrolled` y `Graduate` en un solo valor. \n",
    "\n",
    "-  0 &rarr; `Dropout`\n",
    "-  1 &rarr; `Enrolled` o `Graduate`\n",
    "\n",
    "**Nota**: \n",
    "La siguiente redefinición de atributos genera un desbalance en el atributo `Target`. De todas formas, continuaremos con el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, devel, test]:\n",
    "    df['Target'] = df['Target'].apply(lambda x: 0 if x == 'Dropout' else 1)\n",
    "\n",
    "train['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de atributos continuos.\n",
    "\n",
    "La [discretización](https://en.wikipedia.org/wiki/Data_binning) provee un mecanismo para particionar valores continuos en un número finito de valores discretos.\n",
    "\n",
    "De los [36 atributos presentes](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success) en el dataset, estos son listados como continuos:\n",
    "\n",
    "- `Previous qualification (grade)`\n",
    "- `Admission grade`\n",
    "- `Unemployment rate`\n",
    "- `Inflation rate`\n",
    "- `GDP`\n",
    "\n",
    "Para discretizar estos atributos, utlizaremos el modulo `scikit-learn.preprocessing`. \n",
    "\n",
    "En particular, la clase [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) con los siguientes parámetros:\n",
    "\n",
    "- `encode= 'ordinal'` (codificación de los bins) devuelve un array de enteros indicando a que bin pertenece cada valor.\n",
    "- `strategy='kmeans'` (estrategia de discretizacion) utiliza el algoritmo de [k-means](https://en.wikipedia.org/wiki/K-means_clustering) para determinar los bins. \n",
    "\n",
    "Finalmente, identificar estos atributos en el dataset es una tarea sencilla, ya que son los únicos del tipo `float64`.\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Hay un error en la [documentación de los datos](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success), figuran como discretos dos campos representados con `float64`:\n",
    "\n",
    "- `Curricular units 1st sem (grade)`\n",
    "- `Curricular units 2nd sem (grade)` \n",
    "\n",
    "Decidimos discretizarlos de todas formas, ya que algunas de las entradas tienen valores no enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "float64_cols = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for float64_col in float64_cols:\n",
    "    float64_discretizer = KBinsDiscretizer(subsample=None, encode='ordinal', strategy='kmeans')\n",
    "    train[[float64_col]]    = float64_discretizer.fit_transform(train[[float64_col]]).astype(int)\n",
    "    devel[[float64_col]]    = float64_discretizer.transform(devel[[float64_col]]).astype(int)\n",
    "    test[[float64_col]]     = float64_discretizer.transform(test[[float64_col]]).astype(int)\n",
    "\n",
    "train[float64_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario sobre el resto de los valores (discretos)\n",
    "\n",
    "Los valores discretos son ideales para `ID3` porque el algoritmo puede manejarlos directamente sin necesidad de transformaciones adicionales. Sin embargo, es crucial tener en cuenta el número de valores únicos que un atributo discreto puede tener.\n",
    "\n",
    "Somos conscientes que no existe un \"buen número\" de valores discretos distintos para un atributo en un árbol de decisión como ID3.\n",
    "Depende de varios factores, incluidos el tamaño del conjunto de datos, la complejidad del problema y el riesgo de sobreajuste. \n",
    "\n",
    "Además otro factor a tomar en cuenta es que los valores discretos pueden categorizar elementos complejos donde su valor numérico no tenga correlación con su valor semántico. Por ejemplo, la columna `Nationality` representa con un entero distintos países, si quisieramos categorizar ese valor de forma significativa tendríamos que construir supercategorías para los países (por ejemplo 0-Europa, 1-America, etc).\n",
    "\n",
    "Otra alternativa es aplicar [one-hot encoding](https://datagy.io/sklearn-one-hot-encode/) a los valores discretos, pero esto aumentaría la dimensionalidad del dataset y podría generar problemas de performance.\n",
    "\n",
    "La conclusión final es que el procesamiento de valores discretos es una tarea que excede el objetivo de este laboratorio, por eso decidimos no aplicar ningún preprocesamiento a los valores discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "int64_cols      = data.select_dtypes(include=['int64']).columns\n",
    "unique_values   = data[int64_cols].nunique()\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = unique_values.plot(kind='bar')\n",
    "plt.title('Valores Discretos')\n",
    "plt.xlabel('Atributos')\n",
    "plt.ylabel('Valores Distintos')\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "El algoritmo a desarrollar es `ID3` como se presento en el teórico, con la incorporación de ciertos meta-parametros que buscan evitar el sobreajuste del modelo.\n",
    "\n",
    "Para lograr este objetivo, se tuvo en consideración las siguientes subtareas:\n",
    "\n",
    "1. Sobre las variables/estructuras necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "2. `ID3_utils.py`: Un modulo con estructuras/funciones auxiliares para la implementación de `ID3`.\n",
    "3. `src.G02DecisionTrees.ID3Classifier`: Nuestro algoritmo inspirado en los clasificadores de `sklearn`.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre las variables necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "Para implementar `ID3` necesitamos definir las siguientes variables:\n",
    "\n",
    "Entradas:\n",
    "\n",
    "- `Examples`: conjunto de ejemplos de entrenamiento (`train`).\n",
    "- `Target_attribute`: atributo objetivo (`Target`).\n",
    "- `Attributes`: conjunto de atributos (el resto de las columnas).\n",
    "\n",
    "Estructura de Datos y Funciones Auxiliares:\n",
    "\n",
    "- `node`: estructura de datos que representa un nodo del arbol.\n",
    "- `max_gain_attr`: función que devuelve el atributo con mayor ganancia de información.\n",
    "- `attributes_values`: diccionario que mapea atributos con todos sus valores posibles.\n",
    "\n",
    "\n",
    "Para obtener `attributes_values` recorremos todos los atributos y obtenemos sus valores únicos. Hay que tener en cuenta que los atributos continuos fueron discretizados, por lo que sus valores son enteros que se encuentran en un rango acotado. (Preprocesamiento de atributos continuos).\n",
    "\n",
    "El resto de las Estrucutras de Datos y Funciones Auxiliares se encuentran en el modulo `ID3_utils.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "int64_cols      = data.select_dtypes(include=['int64']).columns\n",
    "attrs_values    = {attr: sorted(data[attr].unique()) for attr in int64_cols}\n",
    "float64_cols    = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "attrs_values.update({col: list(range(5)) for col in float64_cols})\n",
    "\n",
    "print(f'attrs: {len(attrs_values.keys())}, Algunos valores de atributos discretos: \\n')\n",
    "for k in list(attrs_values.keys())[:5]: print(f\"{k}: {attrs_values[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ID3_utils.py`: Un módulo con estructuras/funciones auxiliares para la implementacion de `ID3`.\n",
    "\n",
    "Este módulo de Python está diseñado para implementar árboles de decisión utilizando el algoritmo ID3. A continuación se describen los componentes principales:\n",
    "\n",
    "- `ID3Node`: Esta es una clase que representa un nodo en el árbol de decisión. Cada nodo tiene una etiqueta (`label`) que indica el atributo que se está evaluando en ese nodo, y una ganancia de información (`info_gain`) que indica cuánta incertidumbre se reduce al dividir el conjunto de datos según ese atributo.\n",
    "- `node`: Esta es una función auxiliar que facilita la creación de nuevos nodos. Acepta una etiqueta y una ganancia de información como argumentos y devuelve una instancia de `ID3Node`.\n",
    "- `entropy`: Esta función calcula la entropía de un conjunto de datos dado un atributo objetivo (`attr_tget`). La entropía es una medida de la incertidumbre o el desorden en los datos.\n",
    "- `max_gain_attr`: Esta función determina qué atributo tiene la máxima ganancia de información cuando se utiliza para evaluar el mejor nodo candidato.\n",
    "- `evaluate`: Esta función evalúa un conjunto de datos y busca en el árbol de decisión para determinar la clase de cada ejemplo. Devuelve una lista de predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ID3_utils import max_gain_attr, node\n",
    "\n",
    "attr, gain  = max_gain_attr(train, 'Target', attrs_values)\n",
    "id3_node    = node(attr, info_gain= gain)\n",
    "\n",
    "id3_node.children[attrs_values[attr][0]] = node('Nationality', 0.02)\n",
    "\n",
    "print(f\"node: {id3_node.label, id3_node.info_gain, id3_node.children}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `src.G02DecisionTrees.ID3Classifier`: Nuestro clase-clasificadora inspirada en `sklearn`.\n",
    "\n",
    "Nuestro algoritmo esta encapsulado en una clase clasificadora que está diseñada/inspirada en base a los clasificadores de `scikit-learn`.\n",
    "La principal motivacion para hacerlo de esta forma es el objetivo de comparar los resultados de nuestro algoritmo con los de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "\n",
    "Entonces, consideramos acertado modelar esta clase como si se tratara de una clase más de `scikit-learn.`\n",
    "\n",
    "**Clase ID3Classifier**: Define el clasificador ID3.\n",
    "\n",
    "- `__init__`: Inicializa el clasificador con los meta-parametros. \n",
    "  - `min_samples_split` y `min_split_gain`: requeridas por la letra del obligatorio, limitan el crecimiento del arbol. \n",
    "  - `attr_values`, `attrs` necesarias para implementar `ID3` (Mitchell, 97, p86).\n",
    "\n",
    "`ID3Classifier` implemeneta funciones típicas de `scikit-learn`:\n",
    "\n",
    "- El método `fit` toma un DataFrame `X`, una serie `y` como entrada y construye un árbol de decisión con `_id3`.\n",
    "- El método `predict` utiliza el árbol para hacer predicciones en un nuevo conjunto de datos.\n",
    "- El método `score` evalúa la precisión del modelo utilizando `scikit-learn.accuracy_score`.\n",
    "    \n",
    "**`__id3`** implementa el algoritmo recursivamente para construir el árbol de decisión.\n",
    "\n",
    "```python\n",
    "## Mitchell, p. 68\n",
    "def __id3(self, exs, attr_tget, attrs):\n",
    "    same_value_attr_tget = exs[attr_tget].nunique() == 1\n",
    "    attrs_empty = len(attrs) == 0\n",
    "    \n",
    "    if same_value_attr_tget or attrs_empty: return utils.node(exs[attr_tget].mode()[0])\n",
    "\n",
    "    _attrs_values = { k: self.attrs_values[k] for k in attrs }\n",
    "    best_attr, gain = utils.max_gain_attr(exs, attr_tget, _attrs_values)\n",
    "    \n",
    "    if gain <= self.min_split_gain: return utils.node(exs[attr_tget].mode()[0])\n",
    "    \n",
    "    node = utils.node(best_attr, gain)\n",
    "    best_attr_values = self.attrs_values[best_attr]\n",
    "    \n",
    "    for attr_val in best_attr_values:\n",
    "        exs_i = exs[exs[best_attr] == attr_val]\n",
    "\n",
    "        if exs_i.shape[0] <= self.min_samples_split: \n",
    "          node.children[attr_val] = utils.node(exs[attr_tget].mode()[0])\n",
    "        else:\n",
    "          attrs_i = [attr for attr in attrs if attr != best_attr]\n",
    "          node.children[attr_val] = self.__id3(exs_i, attr_tget, attrs_i)\n",
    "    \n",
    "    return node\n",
    "```\n",
    "\n",
    "***Nota***: \n",
    "\n",
    "Vamos a modificar la columna `Target`  de `train` para forzar la creacion de un ***`dummy classifier`***. En particular uno que siempre prediga `1` (inscripto o graduado). Obtendriamos un arbol de decision con un solo nodo, que siempre predice `1`, y como esta clase esta desbalanceada a favor de `1` obtendremos un accuracy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.G02_decision_trees import ID3Classifier\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']), devel['Target']\n",
    "\n",
    "G02_dumb_clf = ID3Classifier(attrs_values= attrs_values, min_samples_split= 0, min_split_gain= 0.0)\n",
    "G02_dumb_clf.fit(train_X, train_y.apply(lambda x: 1))\n",
    "\n",
    "print(f'{G02_dumb_clf.tree} [\\\n",
    " label: {G02_dumb_clf.tree.label},\\\n",
    " info_gain: {G02_dumb_clf.tree.info_gain},\\\n",
    " children: {G02_dumb_clf.tree.children} ]'\n",
    ")\n",
    "\n",
    "G02_dumb_clf.score(devel_X, devel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación\n",
    "\n",
    "Como se nos ha comentado en el teorico, la evaluación de un modelo es una tarea compleja que requiere de un análisis profundo de los resultados obtenidos.\n",
    "En particular, la seleccion de metricas acorde al problema a resolver es una tarea que requiere de un conocimiento profundo del dominio.\n",
    "\n",
    "Sabemos que el dataset que estamos analizando tiene un desbalance en el atributo objetivo `Target`, por lo que la métrica de `accuracy` no es la más adecuada para evaluar el modelo. Por ejemplo un modelo que siempre prediga un resultado con el valor de una clase favorable, tendra un accuracy elevado (`G02_dumb_clf`) \n",
    "\n",
    "Vamos a utilizar la triada clasica de `precision`, `recall` y `f1-score` para evaluar el modelo. La combinacion de estas tres metricas nos va a dar una imagen mas completa del desempeño del modelo, las tres se encuentran disponibles en el modulo `sklearn.metrics`.\n",
    "\n",
    "- [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "- [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "- [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "Sobre qué conjunto(s) se realiza el entrenamiento, ajuste de la solución, evaluación, etc. Explicar cómo se construyen estos conjuntos.\n",
    "\n",
    "Como ya comentamos anteriormente, nuestro equipo convenientemente separó los datos en tres conjuntos:\n",
    "\n",
    "- `train`: para entrenar el modelo.\n",
    "- `devel`: para ajustar los hiperparametros y evaluaciones intermedias.\n",
    "- `test`: para evaluar el modelo final.\n",
    "\n",
    "Se utilizo una proporcion 60/20/20 para los conjuntos `train`, `devel` y `test` respectivamente. Estos conjuntos ademas se encuentran mezclados de forma aleatoria y estraficados, de forma tal que la proporcion de clases sea la misma en los tres conjuntos.\n",
    "\n",
    "***Nota***:\n",
    "\n",
    "Impremiremos esta proporcion para dejar constancia. De la documentacion de `sklearn.model_selection.train_test_split` se desprende que la estratificacion se hace de forma predeterminada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_proportion = train_y.value_counts(normalize=True)\n",
    "devel_target_proportion = devel_y.value_counts(normalize=True)\n",
    "\n",
    "print(f'Train: {train_target_proportion}\\n')\n",
    "print(f'Devel: {devel_target_proportion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación\n",
    "\n",
    "En este apartado vamos a realizar una serie de experimentos para evaluar el desempeño de nuestro modelo.\n",
    "\n",
    "- Busqueda con Grid Search para encontrar los mejores hiperparametros de nuestro modelo.\n",
    "- Definicion de nuestro modelo final.\n",
    "- Exploracion de los modelos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`.\n",
    "- Comparativa final de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search para encontrar los mejores hiperparametros de nuestro modelo.\n",
    "\n",
    "Para encontrar la mejor combinacion de meta-parametros para nuestro clasificador vamos a utilizar Grid Search. Primero vamos a definir un espacion de busqueda, para eso hay que tomar ciertas precauciones. Sabemos que la idea de los meta-parametros es evitar el sobreajuste del modelo, sin estos elementos, un arbol de decision puede crecer hasta tener un nodo por cada ejemplo de entrenamiento. Por ende, un arbol con muchos nodos es un arbol que esta sobreajustado. De forma analoga, tampoco queremos un arbol que solo tenga un nodo, como el `G02_dumb_clf` que siempre predice `1`.\n",
    "\n",
    "Sabemos que:\n",
    "\n",
    "- `min_samples_split` &rarr; cantidad mínima de ejemplos para generar un nuevo nodo.\n",
    "- `min_split_gain` &rarr; ganancia mínima requerida para partir por un atributo.\n",
    "\n",
    "No satisfacer estas condiciones fuerza la creacion de un nodo hoja con el valor mas comun del atributo objetivo `Target`. Por lo que podemos definir un espacio de busqueda acotado por estos valores.\n",
    "\n",
    "- `min_samples_split` &rarr; (0, 885):\n",
    "    - `min_samples_split` &rarr; 885: Es la cantidad de ejemplos que tiene `devel`.\n",
    "    - `min_samples_split` &rarr; 0: valor predeterminado.\n",
    "\n",
    "En cada iteracion de `ID3` el conjunto de entrenamiento se reduce en factor de cuantos ejemplos habia para el valor del atributo pivotal. Por ejemplo, si el atributo pivotal es `Nationality` y el valor es `Uruguay`, entonces el conjunto de entrenamiento se reduce a los ejemplos que tienen `Nationality == Uruguay`. Si hubiesen 100 ejemplos con `Nationality == Uruguay`, entonces el conjunto de entrenamiento se reduce a 100 ejemplos. En resumen, el conjunto de ejemplos puede reducirse rapidamente a 0, por lo que el limite superior de `min_samples_split` es la cantidad de ejemplos en `devel`, que es un conjunto que tiene menos ejemplos que `train`.\n",
    "\n",
    "- `min_split_gain` &rarr; (0.0, 0.325): La definicion de este espacio esta condicionada por el conjunto train. \n",
    "    - `min_split_gain` &rarr; 0.325: Es la ganacia maxima para un atributo `Curricular units 2nd sem (approved)` en el conjunto `train`\n",
    "    - `min_split_gain` &rarr; 0.0: valor predeterminado.\n",
    "\n",
    "El limite superior, de forma analoga a `min_samples_split`, sino se cumple la condicion de `min_split_gain`, el arbol no crece, corta la recursion en el primer paso.\n",
    "\n",
    "El limite inferior es 0.0 de forma analoga a `min_samples_split`.\n",
    "\n",
    "***Nota***:\n",
    "\n",
    "Entendemos que estos humbrales son arbitrarios y dependientes del conjunto train. Algunas alternativas que se nos ocurrieron fueron:\n",
    "\n",
    "- Eligir una variable pivotal y definir la cota inferior como una proporcion de los elementos de `train`. Por ejemplo, crear una hoja si quedan menos de x% de los ejemplos de `train`.\n",
    "- Eligir la ganancia minima de un atributo en todo `train` como cota inferior. Asi, un arbol no puede crecer si la ganancia de informacion es menor a la ganancia minima en todo el conjunto para un atributo dado. De forma analoga tambien podriamos pivotear esta cota tomando un porcentaje de la ganancia minima de `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ID3_utils import max_gain_attr\n",
    "from src.G02_decision_trees import ID3Classifier\n",
    "from sklearn.metrics import f1_score\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "if os.path.exists('assets/grid_search.csv'): raise Exception('El archivo ya existe')\n",
    "\n",
    "GRID_SAMPLES = 10\n",
    "attr, gain = max_gain_attr(train, 'Target', attrs_values)\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']), devel['Target']\n",
    "\n",
    "meta_params_grid = {\n",
    "    'min_samples_split': np.linspace(devel.shape[0], 0, GRID_SAMPLES).astype(int),\n",
    "    'min_split_gain': np.linspace(gain, 0.0, GRID_SAMPLES)\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=['f1_score', 'min_samples_split', 'min_split_gain'])\n",
    "\n",
    "for min_samples_split in meta_params_grid['min_samples_split']:\n",
    "    for min_split_gain in meta_params_grid['min_split_gain']:\n",
    "        clf = ID3Classifier(attrs_values=attrs_values,\n",
    "                            min_samples_split=min_samples_split, min_split_gain=min_split_gain)\n",
    "        clf.fit(train_X, train_y)\n",
    "        devel_f1_score = f1_score(devel_y, clf.predict(devel_X))\n",
    "        results.loc[len(results)] = [devel_f1_score, min_samples_split, min_split_gain]\n",
    "\n",
    "results.to_csv('assets/grid_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de nuestro modelo final.\n",
    "\n",
    "Despues de realizar 100 iteraciones con grid search, encontramos que la mejor combinacion de meta-parametros es:\n",
    "\n",
    "- `min_samples_split` = 0.0     ;     \n",
    "- `min_split_gain` ~ 0.179506   ;\n",
    "- `f1_score` ~ 0.87636          ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split: 0, min_split_gain: 0.1795057557916415\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.G02_decision_trees import ID3Classifier\n",
    "\n",
    "grid_search = pd.read_csv('assets/grid_search.csv')\n",
    "\n",
    "max_f1_score = grid_search['f1_score'].max()\n",
    "best_params = grid_search[grid_search['f1_score'] == max_f1_score].iloc[0]\n",
    "\n",
    "max_min_samples_split = best_params['min_samples_split'].mean().astype(int)\n",
    "max_min_split_gain = best_params['min_split_gain'].mean()\n",
    "\n",
    "G02_best_clf = ID3Classifier(attrs_values=attrs_values, min_samples_split=max_min_samples_split,\n",
    "                             min_split_gain=max_min_split_gain)\n",
    "                             \n",
    "print(f'min_samples_split: {max_min_samples_split}, min_split_gain: {max_min_split_gain}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploracion de los modelos de `scikit-learn DecisionTreeClassifier, RandomForestClassifer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_X, train_y = train.drop(columns=['Target']), train['Target']\n",
    "devel_X, devel_y = devel.drop(columns=['Target']) , devel['Target']\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(train_X, train_y)\n",
    "dt_clf.score(devel_X, devel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
    "- ¿cuándo se dieron los mejores resultados del jugador?\n",
    "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
    "- ¿cómo mejoraría los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosas de bruno (posiblemente desactualizado ☠️⚰️)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from src.G02_algorithm import CustomID3Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, y_train = train.drop(columns=['Target']), train['Target']\n",
    "\n",
    "custom_clf = CustomID3Classifier(MIN_SAMPLES_SPLIT=0, MIN_SPLIT_GAIN=0)\n",
    "custom_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.drop(columns=['Target']), test['Target']\n",
    "predictions = custom_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='.2f')\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular matrices de confusión\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "cm_random_forest = confusion_matrix(y_test, y_pred_random_forest)\n",
    "\n",
    "## Crear objetos ConfusionMatrixDisplay\n",
    "cmd_decision_tree = ConfusionMatrixDisplay(confusion_matrix=cm_decision_tree, display_labels=decision_tree_clf.classes_)\n",
    "cmd_random_forest = ConfusionMatrixDisplay(confusion_matrix=cm_random_forest, display_labels=random_forest_clf.classes_)\n",
    "\n",
    "# Mostrar las matrices de confusión\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "cmd_decision_tree.plot(cmap=plt.cm.Blues, ax=axes[0])\n",
    "axes[0].set_title(\"Matriz de Confusión - Decision Tree\")\n",
    "\n",
    "cmd_random_forest.plot(cmap=plt.cm.Blues, ax=axes[1])\n",
    "axes[1].set_title(\"Matriz de Confusión - Random Forest\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
